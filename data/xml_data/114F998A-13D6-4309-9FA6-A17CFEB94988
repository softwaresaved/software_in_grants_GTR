<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/0582CA61-7A23-42B3-B744-86F5BF8F9841"><gtr:id>0582CA61-7A23-42B3-B744-86F5BF8F9841</gtr:id><gtr:firstName>Li</gtr:firstName><gtr:surname>Zhaoping</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=ES%2FK006509%2F1"><gtr:id>114F998A-13D6-4309-9FA6-A17CFEB94988</gtr:id><gtr:title>Assessing, understanding, and modeling visual salience and its dynamical impact on perception and selection</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>ES/K006509/1</gtr:grantReference><gtr:abstractText>&lt;p>This project is to study a property of visual attention called 'saliency', which means the strength of a given location in the visual field to attract attention. The project aims to investigate how visual salience dynamically affects attentional and oculomotor selection and how these effects are related to the functional properties of the primary visual cortex (V1) and other brain areas. As a focus so far disregarded in psychological research and modelling, we will concentrate on temporal dynamics. We will experimentally probe salience effects within single fixations as well as those occurring over longer periods of time extending over multiple eye movements, to find out when salience derived from different visual feature dimensions affects visual selection and when not. We will develop a neurophysiologically plausible computational model incorporating the dynamics of salience effects. The model will be based on a salience model of V1 and extended to account for differential salience effects as a function of feature dimension and, importantly, time.&lt;/p></gtr:abstractText><gtr:potentialImpactText>The project is concerned with the fundamental question of how visual salience is represented in the brain, and how it dynamically evolves with time and thus impacts perception of the world and actions on it. Major models on visual perception simplistically assume salience to have persistent effects on selection unless voluntary top-down processes prevent this to happen. We in contrast address the dynamical aspects of salience on visual selection. Behavioral results will be directly related to the brain areas involved. Results will be continually presented on national and international conferences and in international journals.

The non-academic impacts of our project are mainly on the following aspects. First, we live in an age of information explosion. Salience gates the visual information into our perception and behavior through an information bottleneck. Hence, understanding salience helps us to design better information-user interfaces such as images, video, and databases presented via computer screens. Better interfaces will dynamically adapt to the user's need, gaze behavior, and goals, making them most effective on information retrieve (such as in learning, browsing, and data mining) while putting least strain on the user. Secondly, understanding the brain mechanisms underlying salience can help to design visual aids for people with special needs, such as people with brain damages that induce certain blind spots in their visual selection behavior and children needing help in directing their attention in learning. Understanding the temporal dynamics of salience will finally impact robotics. Autonomous mobile robots, for instance in unmanned rescue scenarios or for assistance to elderly people, have to cope with the complexity of their environments. Computing resources have to be traded off against mobility. Understanding the temporal dynamics of salience will provide a new and independent means of achieving efficient performance in their vision.</gtr:potentialImpactText><gtr:fund><gtr:end>2015-12-31</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/924BE15C-91F2-4AAD-941A-3F338324B6AE"><gtr:id>924BE15C-91F2-4AAD-941A-3F338324B6AE</gtr:id><gtr:name>ESRC</gtr:name></gtr:funder><gtr:start>2013-01-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>278252</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The impact of my research is mainly societal and educational. In general terms, its impact is in two areas. Firstly, it is changing people's view so that they start to realize that we humans have many layers of cognitive processes in our seemingly instantaneous visual functions such as visual recognition and visual attention. This view makes people become more aware of their own visual behavior or misbehavior. Secondly, the research outcome is replacing the traditional view of what visual attention is, which brain areas might be responsible for involuntary guidance of our visual attention, and how this involuntary guidance of attention influence our visual perception and recognition.

Some of my research outcome was described in a textbook I wrote, and it is titled &amp;quot;Understanding vision: theory, models, and data&amp;quot;, published by Oxford University Press in 2014. This book helped to educate the general public as well as specialist researchers that vision consists of both looking and seeing, that looking is initially before seeing while seeing guides further looking, and that looking gates what we see. Hence, we can be blind to things in our envionment because we failed to look in the right direction, and that we can be misguided in where we look because what we see could lead us to make a poor decision on where to look next. Such knowledge increases our awareness of the limitions in our vision, which can be manifested in everyday experience such as how magicians work their magics on us and why we cannot necessarily trust our own eyes. 

My research outcome, through the help of my textbook, is also helping to replace the traditional view on how visual attention can be guided involuntarily and which brain areas are responsible for such guidance. Traditionally, it is generally thought that the frontal and parietal brain areas are responsible for guiding our attention, whether the guidance is voluntary or involuntary. My research made a convincing case that the involuntary guidance is done through the primary visual cortex, which is in the occipital lobe of the brain. This has made an impact on new research directions of many young researchers, who have followed up by looking at the primary visual cortex more closely, through methods and approaches such as functional magnetic imaging of the brain activities or electrophysiological experiments on monkeys. It is also linking with research studies on other animals such as rodents, amphibians, and fish. After all, lower vertebrates generally have a smaller frontal brain region, and many do not have neocortex at all. Nevertheless, the lower vertebrates also need to guide their visual attention, and they must do so by the occipital brain area or even the midbrain areas of their central nervous system. This new knowledge and new thinking should have a long lasting impact due to its influence on educating the young brain scientists, whose future research directions will be shaped by these new knowledge from our research outcome.</gtr:description><gtr:firstYearOfImpact>2014</gtr:firstYearOfImpact><gtr:id>6661D9EE-CE7F-49C1-B9A2-EC908E443441</gtr:id><gtr:impactTypes><gtr:impactType>Societal</gtr:impactType></gtr:impactTypes><gtr:sector>Education</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The main discoveries are the following.

(1) The primary visual cortex, the largest visual cortical area in primates like humans, is the sole contributor to computing the map of visual saliency, which is used to guide eye movements and visual attention in visual behavior.

This discovery is very important for the following reasons. First, it has been believed traditionally that this map of visual saliency is computed by higher brain areas such as those in the frontal and parietal areas. This traditional belief has not been helpful in research progress for several decades. Therefore, since our previous works in the late 1990s and early 2000s showing that the primary visual cortex instead computes this saliency map, it has become important to find out whether the primary visual cortex does this alone or together with higher brain areas. Our current discovery that the primary visual cortex is the sole contributor adds an important milestone in the progress of the research community. Second, it has been confusing in the research community regarding the definition of visual saliency, whether it is based on pure exogenous control or it is also based on endogenous control. This confusion is connected with the confusion in the search for the brain substrates that compute the saliency map for guiding visual attention. By nailing down the primary visual cortex as the sole contributor to the saliency map, we clarify further that saliency is exogenously controlled. Third, our discovery enables us to relate the visual attentional behavior in humans with those across the vertebrate species. This is because all animals have visual attentional control to selectively orient to some visual inputs and ignore other visual inputs. However, lower mammals have a smaller neocortex and devote a smaller portion of their neocortex to higher brain areas which have traditionally been thought to compute the saliency map; furthermore, non-mammals such as fish do not have a neocortex, and it is thus puzzling how these animals guide their visual orienting. Our finding that the primary visual cortex, a lower brain area in the neocortex, is the sole contributor to the saliency map enables follow-up works to identify that lower animals use their optic tectum in midbrain to compute a saliency map for guiding attention exogenously, since it is clear from brain anatomy that, in primates, the primary visual cortex sends outputs to the optic tectum to execute visual orienting. 


(2) Properties of visual saliencies can be investigated through brain lesion patients and normal observers who are stimulated by transcranial magnetic stimulation.

With our knowledge about brain areas that contribute to computing saliency, which guide attention exogenously, and our previous knowledge of other brain areas which guide attention endogenously, we have a brain network that controls visual attention and eye movements. It then becomes very important to find out how damages to various brain areas create attentional deficits in patients. For example, some patients can have trouble focusing attention, some have trouble shifting attention from one part of their visual field to another so that they neglect some part of their visual field or environment. With my collaborators, we have compared lesion patients with normal observers in their attentional behavior using carefully designed, diagnostic, cognitive and attentional tasks. We have also used transcranial magnetic stimulation (on normal observers) to perturb certain brain areas in a more controlled and specific manner to observer the consequences of such perturbation in visual attention behavior. We find that such research methods are highly effective and illustrative of the underlying brain mechanisms. These methods can now be used by the wider research community.</gtr:description><gtr:exploitationPathways>Mainly to contribute to the growing knowledge base of the research community, our publications invite good citations and obviously motivating new research investigations by other researchers internationally. 

Secondly, it is likely that we can find our findings useful as diagnostic tool for assessing brain functions in normals and patients.</gtr:exploitationPathways><gtr:id>19EDDC26-7EA2-44E6-BF57-CC4552EC233E</gtr:id><gtr:sectors><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software),Education,Healthcare,Leisure Activities, including Sports, Recreation and Tourism</gtr:sector></gtr:sectors><gtr:url>http://www.cs.ucl.ac.uk/staff/Zhaoping.Li/papers.html</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/3F051316-A544-46B6-AA4E-B07D33A2E08F"><gtr:id>3F051316-A544-46B6-AA4E-B07D33A2E08F</gtr:id><gtr:title>Efficient Coding Theory Predicts a Tilt Aftereffect from Viewing Untilted Patterns.</gtr:title><gtr:parentPublicationTitle>Current biology : CB</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/a62152c799cf061a35f82daba78c1893"><gtr:id>a62152c799cf061a35f82daba78c1893</gtr:id><gtr:otherNames>May KA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0960-9822</gtr:issn></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">ES/K006509/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>790AD28C-6380-4025-83C2-6881B93C4602</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal behaviour</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>E1AC33C6-9927-41AC-B23B-2EED8F593588</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Experimental Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>F439A20B-A9B0-4A68-B703-7F6AE7570E39</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Systems neuroscience</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>