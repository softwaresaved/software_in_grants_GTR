<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/FA776DBE-78D5-49D0-AFA1-77BEC03EFF15"><gtr:id>FA776DBE-78D5-49D0-AFA1-77BEC03EFF15</gtr:id><gtr:name>University of Chichester</gtr:name><gtr:department>Dance</gtr:department><gtr:address><gtr:line1>Bishop Otter Campus</gtr:line1><gtr:line2>College Lane</gtr:line2><gtr:line4>Chichester</gtr:line4><gtr:line5>West Sussex</gtr:line5><gtr:postCode>PO19 6PE</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/FA776DBE-78D5-49D0-AFA1-77BEC03EFF15"><gtr:id>FA776DBE-78D5-49D0-AFA1-77BEC03EFF15</gtr:id><gtr:name>University of Chichester</gtr:name><gtr:address><gtr:line1>Bishop Otter Campus</gtr:line1><gtr:line2>College Lane</gtr:line2><gtr:line4>Chichester</gtr:line4><gtr:line5>West Sussex</gtr:line5><gtr:postCode>PO19 6PE</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/1644C4D9-B45B-493F-BCFC-199D79DE061E"><gtr:id>1644C4D9-B45B-493F-BCFC-199D79DE061E</gtr:id><gtr:firstName>Sarah</gtr:firstName><gtr:surname>Rubidge</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=AH%2FD504090%2F1"><gtr:id>BD34967C-44BA-4EF2-92FD-432229608318</gtr:id><gtr:title>A preliminaray exploration of the choreographic potentical of new motion traking technologies in conjuction with interctive ambisonic surround sound</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>AH/D504090/1</gtr:grantReference><gtr:abstractText>In the last year two new technologies which are appropriate for use in interactive performance have become available. One is a new tracking technology which has recently been developed collaboratively by SurroundAV (UK) and V2 (Netherlands). The motion tracking system compromises a small wearable device, constituting RF technology in combination with ultra sound and acceleromator sensors, and a small custom built wearable computer device. These track the spatial trajectories, exponential velocity and acceleration of performers as they move through space. This negates the need for the camera-based tracking technologies which have previously tended to be used in live interactive performance. The new system thus has the potential to supercede motion tracking technologies previously used by interactive performance artists (e.g VNS, Eyecon, BigEye, Cyclops) and to overcome problems they present in live performance contexts, e.g. the need for stable lighting conditions, limitations on size of 'sensed-space' and occlusion of one performer by another.\n\nThe other recent development is an interactive ambisonic surround sound system that generates a three-dimensional sonic environment in which the sonic reach, as well as direction and texture of sound, can be manipulated. This means that sonic art now has the potential to become, like dance, a space-time art form. Previously unavailable to choreographers this new, interactive, system offers sonic/choreographic artists exciting possibilities for a development of complex compositions in which both sound and movement exploit spatial dimensions (choreo-sonic performance events).\n\nAmongst the latter are new choreographic possibilities for interactive performance e.g. the composition of complex, integrated spatial structures in three dimensions in both sound, and movement. Although there has been some research into the use of the 'living architecture' of human movement to generate sound environments in realtime (Denny, Mitchell and Lovell, 1996; Ng Popat et al, 2000; Palindrome 2000/2004) little research has taken place on mapping human movement to ambisonic 3d sound spatialization. Further, whilst previous research tended to focus on the architecture of individual dancers' movement in this research project choreographic concepts relevant to the development of a collective (group) 'living architecture', designed with an emergent sonic architecture in mind, will be explored.\n\nPreliminary compositional research into the new possibilities offered by the two systems will be conducted with sonic artist Stan Wijnans, specialist in interactive performance systems and ambisonics surround sound. Choreographic strategies will be devised in the systems with live performers, with a view to generating structures appropriate for a composite 'choreo-sonic' performance event. The research wil be practice-led, comprising 3 research periods, 2 in Rotterdam where the prototype system is housed, 1 in London, and interim evaluation meetings between workshops. During the workshops the systems will be explored, and choreographic devices developed to suit the needs of technological systems, and modifications made to the system relevant to artistic needs. In the final workshop in the UK, the devices and strategies will be refined and a prototype compositional system devised, culminating in a public presentation of the results of the research to the researchers, artists and others interested in interactive performance technologies.\n\nIf the two technological systems researched in this project are found to be appropriate for interactive choreographic work, both systems would be of great benefit to the interactive performance community, contributing to accessibility to a greater range of compositional possibilities, a greater range of venues, and a richer sound environment for interactive performance events</gtr:abstractText><gtr:fund><gtr:end>2006-10-31</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/1291772D-DFCE-493A-AEE7-24F7EEAFE0E9"><gtr:id>1291772D-DFCE-493A-AEE7-24F7EEAFE0E9</gtr:id><gtr:name>AHRC</gtr:name></gtr:funder><gtr:start>2006-05-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>7979</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">AH/D504090/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>7B8CDA14-FE2F-4F7C-BCD4-87F84927DAC0</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Dance</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>0AEFDABE-67A4-48B1-9DB4-99393BDE6065</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Music</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>39E7FE7A-475D-49A2-8F6F-DE29A0DC74B1</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Choreography</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>A13304AD-8058-4333-86C7-DB798216A696</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Composition</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>