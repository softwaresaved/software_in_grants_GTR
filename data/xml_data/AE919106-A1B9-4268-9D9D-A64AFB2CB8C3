<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:department>Oxford e-Research Centre</gtr:department><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/A0BA6F53-EE93-4C3C-AB30-980124655C2C"><gtr:id>A0BA6F53-EE93-4C3C-AB30-980124655C2C</gtr:id><gtr:firstName>Min</gtr:firstName><gtr:surname>Chen</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/0ABD1A0D-7315-468D-91DD-627D0E5671A4"><gtr:id>0ABD1A0D-7315-468D-91DD-627D0E5671A4</gtr:id><gtr:firstName>Ian</gtr:firstName><gtr:otherNames>Michael</gtr:otherNames><gtr:surname>Thornton</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FG006555%2F2"><gtr:id>AE919106-A1B9-4268-9D9D-A64AFB2CB8C3</gtr:id><gtr:title>Illuminating the Path of Video Visualization</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/G006555/2</gtr:grantReference><gtr:abstractText>The notion of video visualization was coined by the PI and his postgraduate student in their 2003 IEEE VIS paper. It is a technology drawing the concepts and methodologies from volume and flow visualization, image and video processing, and vision science. It extracts meaningful information from a video data set and conveys the extracted information to users in appropriate visual representations. It is not intended to provide fully automatic solutions to the traditional problems in video processing, but involves human in the loop of intelligent reasoning while reducing the burden of viewing videos. In the subsequent work in collaboration with Stuttgart, the PI and CI introduced the concept of visual signatures in video visualization, and reported a major user study conducted at Swansea involving some 92 subjects [IEEE TVCG 2006]. This work offered an important scientific insight as to how human observers may learn to recognize visual signatures of events depicted in an abstract visual representation of a video.[Tsotsos01] stated that a bounded visual search (e.g., looking for all moving pixel clusters with 20-60 pixels) can be achieved in linear time, whist an unbounded visual search (e.g., looking for something abnormal in a video) is NP-complete. For most practical problems in video processing and computer vision, we rarely have perfectly bounded visual search. We often search simultaneously for entities (e.g., objects, motions or events) in different classes. The models that are used to guide a search are usually incomplete and may lead to uncertainty or errors in detection, segmentation andclassification. The dynamic and unpredictable nature of the input videos instigates mechanisms for heuristic reasoning and iterative decision optimization, which further depart from linear or polynomial performance.In contrast, the human eye-brain system is undeniable more powerful than any current vision system in performing visual searches, especially unbounded visual searches. Even we suppose that the human eye-brain system is a Turing machine, its 100 billion neurons and 100-500 trillion synaptic connections between neurons will unlikely to be matched by computers in the near future. Hence this raises the possibility that using video visualization to aid unbound visual search may provide a more scalable means for dealing with large volumes of video datasets.Video visualization can be deployed in many application areas, such as scientific experimentation and computation, security industry and media and entertainment industry. However, in traditional visualization (e.g., medical visualization), the users are normally familiar with the 3D objects (e.g., bones or organs) depicted in a visual representation. In contrast, human observers are not familiar with the 3D objects depicted in a visual representation of a video because one spatial dimension of these objects shows the temporal dimension. The problem is further complicated by the fact that, in most videos, each 2D frame is the projective view of a 3D scene. Hence, a visual representation of a video on a computer display is, in effect, a 2D projective view of a 4D spatiotemporal domain. In order to for us to see 'time' without using 'time', we need to address a range of challenges in science, technology, visual perception and applications. This project is intended to continue the UK's leadership in tackling these challenges by building on the existing expertise and excellence in video visualization.</gtr:abstractText><gtr:fund><gtr:end>2013-09-29</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2011-06-30</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>371463</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>This research [2009-2014] has generated a large collection of research results including a major theoretical paper as well as several applications (sports, biology transport and security). Over 20 papers (including 17 journal papers) resulted from this project.</gtr:description><gtr:firstYearOfImpact>2010</gtr:firstYearOfImpact><gtr:id>452230A5-C6F7-4D82-A400-035D88184F03</gtr:id><gtr:impactTypes/><gtr:sector>Leisure Activities, including Sports, Recreation and Tourism,Pharmaceuticals and Medical Biotechnology,Security and Diplomacy</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>Summarizing a video into a single picture can significantly save the time of viewing videos in many applications. This research has proven the feasibility through a number of applications including sports (snooker, rugby), biological videos, traffic videos, satellite images, movie sound annotation, and so on.</gtr:description><gtr:exploitationPathways>This project has resulted over 20 publications, including 17 journal papers. Two PDRAs who worked on the project have become faculty members. Video visualization is becoming a subject in visualization, and sports video visualization became a popular topic in 2014.</gtr:exploitationPathways><gtr:id>EFDDCE51-1343-4845-9307-097C4F08DFA1</gtr:id><gtr:sectors><gtr:sector>Aerospace, Defence and Marine,Construction,Digital/Communication/Information Technologies (including Software),Environment,Healthcare,Leisure Activities, including Sports, Recreation and Tourism,Manufacturing, including Industrial Biotechology,Pharmaceuticals and Medical Biotechnology,Security and Diplomacy,Transport</gtr:sector></gtr:sectors><gtr:url>http://www.oerc.ox.ac.uk/projects/illuminating-path-video-visualization</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/30EE845F-CBED-47C1-BA92-302F0FB22828"><gtr:id>30EE845F-CBED-47C1-BA92-302F0FB22828</gtr:id><gtr:title>Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop</gtr:title><gtr:parentPublicationTitle>IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/dea4f012f5d06795ad2c194041a00be9"><gtr:id>dea4f012f5d06795ad2c194041a00be9</gtr:id><gtr:otherNames>Legg Philip A.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1077-2626</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/2AABD777-3496-46BF-AADF-CD926C50525D"><gtr:id>2AABD777-3496-46BF-AADF-CD926C50525D</gtr:id><gtr:title>Knowledge-Assisted Ranking: A Visual Analytic Application for Sports Event Data.</gtr:title><gtr:parentPublicationTitle>IEEE computer graphics and applications</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/e5dc7540aadfe9be688802a3270d9db0"><gtr:id>e5dc7540aadfe9be688802a3270d9db0</gtr:id><gtr:otherNames>Chung DH</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0272-1716</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/FB91E226-7383-411E-BDA6-AB84ED49974E"><gtr:id>FB91E226-7383-411E-BDA6-AB84ED49974E</gtr:id><gtr:title>Facial expression recognition in dynamic sequences: An integrated approach</gtr:title><gtr:parentPublicationTitle>Pattern Recognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/08a75634aa9b91bf15eea5f439f4c185"><gtr:id>08a75634aa9b91bf15eea5f439f4c185</gtr:id><gtr:otherNames>Fang H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0031-3203</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/C0A6DBA2-97CA-42DE-8FA4-7E4290B03C20"><gtr:id>C0A6DBA2-97CA-42DE-8FA4-7E4290B03C20</gtr:id><gtr:title>Complexity Plots</gtr:title><gtr:parentPublicationTitle>Computer Graphics Forum</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/4ec412712d0fd2a41830a72a22287fa9"><gtr:id>4ec412712d0fd2a41830a72a22287fa9</gtr:id><gtr:otherNames>Thiyagalingam J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>0167-7055</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/F598A27C-BAA2-467C-AE6F-09540B4AD3ED"><gtr:id>F598A27C-BAA2-467C-AE6F-09540B4AD3ED</gtr:id><gtr:title>Information Theory Tools for Visualization</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/4b89fde57071e81d0ee24b334c3b406a"><gtr:id>4b89fde57071e81d0ee24b334c3b406a</gtr:id><gtr:otherNames>Chen Min</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:isbn>9781498740937</gtr:isbn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/97780EDD-1DFE-4AD0-B93D-485459B1B9D5"><gtr:id>97780EDD-1DFE-4AD0-B93D-485459B1B9D5</gtr:id><gtr:title>Vehicle object retargeting from dynamic traffic videos for real-time visualisation</gtr:title><gtr:parentPublicationTitle>The Visual Computer</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/e616db0be15fe06e30047e7ee08212ca"><gtr:id>e616db0be15fe06e30047e7ee08212ca</gtr:id><gtr:otherNames>Walton S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>0178-2789</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/66122E8A-A640-4B97-96D5-02829B0ED43E"><gtr:id>66122E8A-A640-4B97-96D5-02829B0ED43E</gtr:id><gtr:title>Glyph sorting: Interactive visualization for multi-dimensional data</gtr:title><gtr:parentPublicationTitle>Information Visualization</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/c924e8dba19de632ed9b9e85bad65a06"><gtr:id>c924e8dba19de632ed9b9e85bad65a06</gtr:id><gtr:otherNames>Chung D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1473-8716</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/C5F0A571-FEF9-4D53-B940-927E79841B4C"><gtr:id>C5F0A571-FEF9-4D53-B940-927E79841B4C</gtr:id><gtr:title>Visualizing multiple error-sensitivity fields for single camera positioning</gtr:title><gtr:parentPublicationTitle>Computing and Visualization in Science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/c924e8dba19de632ed9b9e85bad65a06"><gtr:id>c924e8dba19de632ed9b9e85bad65a06</gtr:id><gtr:otherNames>Chung D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>14330369</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/1F417BDF-04E3-4E47-9CE1-91B69E8F5B24"><gtr:id>1F417BDF-04E3-4E47-9CE1-91B69E8F5B24</gtr:id><gtr:title>Glyph-Based Video Visualization for Semen Analysis.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on visualization and computer graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/b535056ba91988324a568b643f754968"><gtr:id>b535056ba91988324a568b643f754968</gtr:id><gtr:otherNames>Duffy B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1077-2626</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/BBEAE47A-F91C-49BC-B77E-9667AF43C7A1"><gtr:id>BBEAE47A-F91C-49BC-B77E-9667AF43C7A1</gtr:id><gtr:title>Temporal Visualization of Boundary-based Geo-information Using Radial Projection</gtr:title><gtr:parentPublicationTitle>Computer Graphics Forum</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/5233e740fde6c77a056ba0089aa0294c"><gtr:id>5233e740fde6c77a056ba0089aa0294c</gtr:id><gtr:otherNames>Drocourt Y</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/G006555/2</gtr:identifier></gtr:identifiers><gtr:projectHierarchy><gtr:parents><gtr:parent><gtr:id>C37E12FF-953B-4528-9842-8762144502D0</gtr:id><gtr:grantRef>EP/G006555/1</gtr:grantRef><gtr:amount>843148.41</gtr:amount><gtr:start>2009-02-01</gtr:start><gtr:end>2011-06-30</gtr:end><gtr:children><gtr:child rel="Transfer"><gtr:id>AE919106-A1B9-4268-9D9D-A64AFB2CB8C3</gtr:id><gtr:grantRef>EP/G006555/2</gtr:grantRef><gtr:amount>371463.6</gtr:amount><gtr:start>2011-06-30</gtr:start><gtr:end>2013-09-29</gtr:end><gtr:children/></gtr:child></gtr:children></gtr:parent></gtr:parents></gtr:projectHierarchy><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>A704B681-6133-41A6-8D93-905FFEC6353B</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Computer Graphics &amp; Visual.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>