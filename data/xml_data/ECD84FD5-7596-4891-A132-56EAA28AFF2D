<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/A8967420-49D3-4509-9912-25FB3EC75B74"><gtr:id>A8967420-49D3-4509-9912-25FB3EC75B74</gtr:id><gtr:name>University of Sussex</gtr:name><gtr:department>Sch of Life Sciences</gtr:department><gtr:address><gtr:line1>The Administration</gtr:line1><gtr:line2>Sussex House</gtr:line2><gtr:line3>Falmer</gtr:line3><gtr:line4>Brighton</gtr:line4><gtr:line5>East Sussex</gtr:line5><gtr:postCode>BN1 9RH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/A8967420-49D3-4509-9912-25FB3EC75B74"><gtr:id>A8967420-49D3-4509-9912-25FB3EC75B74</gtr:id><gtr:name>University of Sussex</gtr:name><gtr:address><gtr:line1>The Administration</gtr:line1><gtr:line2>Sussex House</gtr:line2><gtr:line3>Falmer</gtr:line3><gtr:line4>Brighton</gtr:line4><gtr:line5>East Sussex</gtr:line5><gtr:postCode>BN1 9RH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/AD5962E5-7606-48D1-9359-3622A2927223"><gtr:id>AD5962E5-7606-48D1-9359-3622A2927223</gtr:id><gtr:firstName>Daniel</gtr:firstName><gtr:surname>Osorio</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=BB%2FL008483%2F1"><gtr:id>ECD84FD5-7596-4891-A132-56EAA28AFF2D</gtr:id><gtr:title>From Measurements to Objects: Multidimensional Generalisation and Categorisation in Chicks</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/L008483/1</gtr:grantReference><gtr:abstractText>Although seemingly effortless, our ability to visually recognise and classify objects is impressive. We are a long way from understanding the principles of object recognition implemented in the brain, or from matching them in machine vision. In essence the eye, like all sense organs, makes physical measurements of stimuli, which we recognise as colour, pattern, shape and so-forth. For a given class of object, a difference in any given measure, or dimension, may or may not be relevant. For example, dogs vary more in size than cats, and the colour of a strawberry is more informative about its edibility than the colour of an apple. Animals have to learn which dimensions of variation are significant, which are irrelevant, and how variations on different dimensions - such as colour and size - are related.
 
The basic question is whether a newly encountered Object-Z is of the same kind as previously encountered Objects-X, Objects-Y or completely novel. How do animals learn abut X's and Y's, and then apply this knowledge to Z? Two problems complicate research on this question: firstly, the animal's decision will be based not only on its controlled and known experimental experience, but also on uncontrolled and unknown experience from the rest of its life. Secondly, we do not know what measures (or perceptual dimensions) animals use to represent natural objects. To solve these problems we train young chicks to find food in paper containers, which are printed with colour patterns. Chicks naturally peck at the containers. They learn quickly and accurately which colours predict food, and which are unprofitable. Given new colours their pecking rate shows which colours the birds believe are most like those of previously trained food parcels. Crucially, we can control all of the chicks' previous experience, and we can define colour precisely in a way that is not feasible with other stimuli.

The problem of classifying natural objects has no straightforward solution. The brain processes vast quantities of sense data, and the best solution for any realistic computational strategy is unknown. This project will test the three main theoretical accounts of how animals - or any system - should classify complex signals. Two of these are established in the behavioural and psychological literature. The third is based our own previous work, and will be developed as part of the project.
 
The first class of model (including the Delta Rule and Rescorla-Wagner models) is widely applied in animal-learning, and also in neural network applications that used in applications from engineering to credit rating. Secondly, there are &amp;quot;exemplar&amp;quot; models, which store every previous experience, and are widely applied in human psychology. The third class is a simple &amp;quot;generative&amp;quot; model of object recognition, which we have developed. Generative models solve the difficult problem of going from images to objects, by starting from simple problem of going from objects to images: they ask &amp;quot;if there was an apple, what would I see?&amp;quot; The solution to the easy problem - from objects to measurements -, is turned into the solution we want - from measurements to objects -, by the mathematical identity known as Bayes' rule. Bayesian models are conceptually elegant, simple to use, and highly effective. They have many applications in modern science, but have not so far in work on visual object recognition.
 
The models make clear and distinct predictions about how to classify stimuli that vary on multiple dimensions (say hue' and 'saturation'), which we will test by observing chicks' preferences for novel coloured food containers.</gtr:abstractText><gtr:technicalSummary>Object recognition is essential for almost any visual system, whether biological or artificial. The fundamental problem is that sensory systems can discriminate more stimuli than there are relevant responses. Indeed the physical stimuli that a given object generates are most unlikely to be identical on separate encounters - due to changes in viewing distance, direction and in illumination. At the same time small differences are sometimes highly relevant to behavioural decisions, and it is clear that sensory systems have evolved to make fine judgments. The problem is to determine the significance of variations in complex (i.e. multidimensional) sensory stimuli. The system must learn from examples and then apply a statistical model of variation to (quickly) classify novel stimuli. Not only is this a major challenge in human and machine vision, but research on animal sensory generalization lags behind work on other aspects of associative leaning, both experimentally and theoretically.

We have shown that young chicks learn colour very accurately and quickly when they are foraging for food. The birds' ability to make fine discriminations allows us to test how they then generalise across large colour differences. We also have the advantage that colour stimuli form a continuum that can be defined in terms of receptor excitations: differences can be parameterized in terms of discrimination thresholds. These features have allowed major advances over previous work on sensory generalization. Our data are not consistent with current 'textbook' theories of discrimination learning, which has led us to develop a Bayesian model that works well for sensory generalization on a single stimulus dimension.
 
The proposed study will elaborate this Bayesian model of multiple stimulus dimensions. And makes testable predictions that are different from currently predominant models (delta rule and GCM). We will test these predictions with seven sets of experiments.</gtr:technicalSummary><gtr:potentialImpactText>Industrial

Both Applicants have a strong track-record for industrial collaboration and knowledge transfer. Including a Patent on colour measurement (Osorio), and ten industrial and CASE studentships over the past decade. 

For this study there is potential for wider applications in the two main areas:
1. The design of visual communication and camouflage signals and patterns, for security and safety applications. 
2. For machine vision and decision making, where both the theoretical models and their empirical validation address long-standing problems in automated object recognition and signal classification.

Both types of application can be initiated during the projects lifetime via existing links and collaborations. Baddeley is a member of the Bristol Vision Institute (BVI), includes academic scientists from Life Sciences, Psychology, Mathematics and Engineering as well as industrial partners working in machine vision. At present he has a joint project with Engineering and Industrial partner in a related area of machine learning concerned with classification of natural images. Baddeley is also a member of the EPSRC funded project on 'Decision making in an unstable world', which is concerned with wider application of models that will be developed in this study.
Public engagement.

Animal colour vision and cognition both have wide appeal, and both applicants have had broad national and international exposure of work in the area, by the BBC, popular scientific press, web-logs and so forth. 

Specifically we will generate a JavaScript based web site on bird colour vision, and colour categorization. The web site will consist of four simple stages which can be hosted by a science museum or independently. This site will introduce bird colour vision and explain how it is used in natural behaviour. It will then allow users to take a 'test' comparable to the chickens, allowing us at one level to show how 'good' animals are at certain tasks, and also in a direct and graphical manner to explain the basic concepts of signal variation and stimulus classification that lie at the heart of the science in this proposal. The total time on the site we estimate to be about 4 minutes.

Staff Development. 

The Post Doctoral Researcher will develop skills in colour measurement, and state of the art signal classification algorithms and their application to real-world signals. There is substantial demand for these skills. Previous post-docs and students have found employments in areas such as medical imaging, security technology, analysis of x-ray signals and visual image analysis.</gtr:potentialImpactText><gtr:fund><gtr:end>2017-08-31</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2014-09-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>37978</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The project began in September 2014. Since then we have developed a new experimental methodfor evaluating how chicks learn about differences between 'good' (rewarded) and 'bad' (unrewarded) colours associated with food, and generalise this knowledge to new colours. The experimental data have been fitted with a new mathematical model of sensory discrimination, known as a psychometric function, which potentially has wide application.

This work represents the first part of the proposed project, further experiments are underway.</gtr:description><gtr:exploitationPathways>The methods and models are being extended in a feasibilty study of colour categorizaiton and learning in human infants, and may also be applied to adults.</gtr:exploitationPathways><gtr:id>69F6831C-C978-465E-BBC4-7EA028FE0B78</gtr:id><gtr:sectors><gtr:sector>Agriculture, Food and Drink,Digital/Communication/Information Technologies (including Software)</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/DF1CD869-595D-4415-B803-E7BC0FD6F7B2"><gtr:id>DF1CD869-595D-4415-B803-E7BC0FD6F7B2</gtr:id><gtr:title>Color generalization across hue and saturation in chicks described by a simple (Bayesian) model.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/efb12755a6c96db6d61a747dad8dc72a"><gtr:id>efb12755a6c96db6d61a747dad8dc72a</gtr:id><gtr:otherNames>Scholtyssek C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/L008483/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>D5C57767-F44D-42BE-B074-C153A3C8EEA2</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal Welfare</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>790AD28C-6380-4025-83C2-6881B93C4602</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal behaviour</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>E457FFDE-A4C1-4907-AE12-A394D95A3AE5</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Cognitive Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>F439A20B-A9B0-4A68-B703-7F6AE7570E39</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Systems neuroscience</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>