<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/7A0397DD-E0C6-4EA3-8031-B841D2503C4D"><gtr:id>7A0397DD-E0C6-4EA3-8031-B841D2503C4D</gtr:id><gtr:name>Royal Holloway, University of London</gtr:name><gtr:department>Psychology</gtr:department><gtr:address><gtr:line1>Egham Hill</gtr:line1><gtr:line4>Egham</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>TW20 0EX</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/7A0397DD-E0C6-4EA3-8031-B841D2503C4D"><gtr:id>7A0397DD-E0C6-4EA3-8031-B841D2503C4D</gtr:id><gtr:name>Royal Holloway, University of London</gtr:name><gtr:address><gtr:line1>Egham Hill</gtr:line1><gtr:line4>Egham</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>TW20 0EX</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/3DB4B91C-1369-4567-98CA-202E611E60D3"><gtr:id>3DB4B91C-1369-4567-98CA-202E611E60D3</gtr:id><gtr:firstName>Kathleen</gtr:firstName><gtr:surname>Rastle</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/F3F9D622-20E8-4B45-8526-AA85085D9B50"><gtr:id>F3F9D622-20E8-4B45-8526-AA85085D9B50</gtr:id><gtr:firstName>Marc</gtr:firstName><gtr:surname>Brysbaert</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=BB%2FE003419%2F1"><gtr:id>8DE85099-13A0-43C6-955A-4834628CF441</gtr:id><gtr:title>Selection for Action: Interference Effects on the Articulation of Speech Sounds</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/E003419/1</gtr:grantReference><gtr:abstractText>Speech production is one of the most fundamental of human abilities and its breakdown can have devastating consequences for individuals. Despite this, there is no comprehensive theory of the cognitive and articulatory processes involved in normal speech production or of the diverse ways in which these processes may be impaired through abnormal development or brain injury. One difficulty in formulating such a theory is that the two broad levels of processing underlying speech production have typically been treated within two distinct disciplines. On one side, cognitive psychologists have used one set of methods to study the processes through which we compute an abstract code for the sounds that we intend to produce. On the other side, phoneticians have used another set of methods to study how we translate this abstract code into the articulatory movements that produce an acoustic signal. Our research project brings these disciplines together in pursuit of a more complete theory of speech production than has so far been developed. The specific aim of our research project is to determine how information flows across these two broad levels of processing in speech production. Speech production researchers have generally made an assumption that the relationship between these levels of processing is 'staged'. Essentially, this means that they have assumed that an abstract code for sound must be computed fully before the motor system can begin to compute the programs associated with appropriate articulatory movement. The view that these two broad levels of processing are accomplished in discrete stages has allowed researchers to them as largely separate problems. However, this fundamental assumption about how the speech production system operates has never been tested in a concentrated manner, and in fact has been challenged by recent findings. Our research will test this core assumption thoroughly, in a series of several experiments that use an innovative interdisciplinary method recently developed in our laboratory. This method quantifies highly-specific influences of ignored distractor syllables (e.g., KEY) on the articulation of target syllables (e.g., CORE) using fine-grained articulatory and acoustic techniques imported from experimental phonetics. Our research will ask whether, and under which experimental circumstances, visual and auditory distractor syllables leave systematic 'traces' of themselves on the otherwise accurate production of target syllables. Such traces would indicate that motor programs are computed automatically for the ignored distractor syllables, and compete with the motor programs associated with the articulation of target syllables. These findings would challenge the staged model of speech production assumed by most researchers in the field, since on that model information about distractors not selected for production cannot be passed to the motor systems involved in articulation. The findings of this research project may therefore have major theoretical implications for our understanding of the processes underlying speech production. It is also expected that the innovative method advanced in this project will advance the range of tools available for the scientific study of normal and impaired speech production.</gtr:abstractText><gtr:technicalSummary>Speech production is generally characterised in terms of two broad levels of processing. One of these levels of processing concerns the computation of an abstract phonological code from print or conceptual knowledge; the other of these levels of processing concerns the implementation of that code as articulatory movement resulting in an acoustic speech signal. Speech production researchers have typically assumed that activity across these two levels of processing is staged, such that an abstract phonological code must be computed fully before the motor system can begin to compute the programs associated with appropriate articulatory movement. This fundamental assumption has never been tested in a concentrated manner, however, and recent evidence has begun to put it into doubt. Our research will test this assumption thoroughly, in a series of several experiments that use an innovative interdisciplinary method recently developed in our laboratory. This method quantifies highly-specific influences of ignored distractor syllables (e.g., KEY) on the articulation of target syllables (e.g., CORE) using fine-grained articulatory and acoustic techniques imported from experimental phonetics. Our research will ask whether, and under which experimental circumstances, visual and auditory distractor syllables leave systematic 'traces' of themselves on the otherwise accurate production of target syllables. Such traces would be similar to those recently quantified in the literature on reaching and grasping, and would indicate that motor programs are computed automatically for unselected distractor syllables. These findings would challenge staged models of speech production, and would instead suggest that information flows in cascade across broad levels of the speech production system.</gtr:technicalSummary><gtr:fund><gtr:end>2010-12-02</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2007-01-03</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>289571</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/28E7740B-B83B-453B-BFEB-9E33D2FA5EFC"><gtr:id>28E7740B-B83B-453B-BFEB-9E33D2FA5EFC</gtr:id><gtr:title>Activation of articulatory information in speech perception.</gtr:title><gtr:parentPublicationTitle>Proceedings of the National Academy of Sciences of the United States of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/4e55c6da85bbb31d6295235a2f66766c"><gtr:id>4e55c6da85bbb31d6295235a2f66766c</gtr:id><gtr:otherNames>Yuen I</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>0027-8424</gtr:issn></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/E003419/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>