<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Ear Institute</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/1318ADD8-85A3-4FDE-816A-99386CE74212"><gtr:id>1318ADD8-85A3-4FDE-816A-99386CE74212</gtr:id><gtr:firstName>Jennifer</gtr:firstName><gtr:otherNames>Kim</gtr:otherNames><gtr:surname>Bizley</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=BB%2FN001818%2F1"><gtr:id>FD4B13F3-8847-4449-AC2B-791C4D3868F2</gtr:id><gtr:title>Selective Attention: How does Neural Response Modulation in Auditory Cortex Enable Auditory Scene Analysis?</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/N001818/1</gtr:grantReference><gtr:abstractText>Listening to conversation in a crowded room is one of the greatest challenges that the auditory system faces, and the most common cause of complaint for many of the 10 million people in the UK who suffer hearing loss. For example, to fully appreciate the piece of gossip that your friend is telling you in a restaurant, you must be able to separate his voice from the voices of other people, the clatter of glasses, and the music playing in the background. Your brain is able to 'select' the voice of your friend over all these other sounds - perhaps on the basis of where he is standing, or the pitch of his voice. Normal hearing listeners achieve this feat effortlessly, although engineers have yet to create a machine that can successfully match such signal separation in noisy backgrounds. In this proposal we try to understand how the neural machinery of the brain is able to extract sounds of interest while ignoring others. Our work focuses on a brain area called the auditory cortex; an area that is thought to be necessary for listening in complex situations like the one described above. Our goal is to understand how the responses of neurons in auditory cortex represent multiple competing sounds, and how the neural responses can be shaped in order to best represent sounds according to the listener's current demands.

In this proposal we train animals in a series of listening tasks that will enable us to impose different demands on auditory cortex. Animals will listen for a target word amongst a series of non-target words. In some cases they will do this in silence, in others in the presence of background noise. In further variations they will listen to two streams of speech, each from a different talker, and from different locations, and be asked to selectively attend to one talker over the other (equivalent to trying to listen to your friend while ignoring the loud man behind her). We will record from neurons in auditory cortex while animals perform these tasks in order to understand how the different task requirements change the way in which sounds evoke neural activity. Auditory cortex is made of multiple, hierarchically organised areas that are thought to perform different functions. We will determine whether areas early in this hierarchy are affected by attention differently from those in higher areas.

In the second part of this project we will use a technique called optogenetics to selectively silence neural activity in particular regions of auditory cortex. We will test the hypothesis that different areas of Auditory Cortex facilitate different sorts of attention - for example separating sounds according to their location in space, as opposed to the pitch or timbre or a particular talker's voice. Finally we will determine whether feedback from higher auditory areas to primary auditory areas is essential for active listening. This work would represent a fundamental advance in our knowledge of the role of these 'feedback' projections and the role that they play in active listening.

Our work has the potential to enable the development of more sophisticated, biologically inspired, signal processing devices for hearing aids and cochlear implants - both of which perform poorly in many real-world listening conditions. Listeners whose hearing is assessed via an audiogram as normal can still struggle with listening in noisy situations - this problem is particularly acute in aged listeners. Problems in processing complex sounds underlie Central Auditory Processing Disorder, and disorders of attention are thought to underpin a variety of developmental disorders including autism, attention related hyperactivity disorder, as well as dementia and other neuropsychiatric conditions. Understanding the neural mechanisms in the healthy brain responsible for engaging attention to select sources in a sound scene will lay the foundation for understanding, and potentially treating, conditions in which these mechanisms are impaired.</gtr:abstractText><gtr:technicalSummary>Our goal is to understand how active listening shapes neural responses in auditory cortex (AC), and to determine whether and when feedback connections from non-primary to primary areas facilitate selective attention. Real-world hearing is made challenging by the presence of multiple competing sound sources. Thus, listeners must direct their attention to a source of interest while ignoring others. Recent studies, utilising imaging techniques or ECoG recordings in humans, have demonstrated that neural activity in non-primary AC represents predominantly attended sound sources, yet little is known about the physiological mechanisms that facilitate this. 

In this proposal we seek to determine how single cell responses in AC are shaped by current task demands. We will record from the AC of animals actively discriminating speech sounds and trained to report the occurrence of a target word. By employing different variants of the same paradigm we will determine how attentional mechanisms influence stimulus representation. These include a single stimulus stream in silence, conditions in which there is a competing stream of masking noise and a selective-attention task where animals discriminate one of two competing speech streams. We will test the hypothesis that spatial and feature based attentional mechanisms have different auditory cortical loci. We will assess whether changes to single neuron receptive fields are best summarised as gain changes. 

Attention related changes in sensory representations are thought to result from feedback connections from secondary to primary Auditory Cortex areas. We will address this hypothesis by determining the behavioural consequences of inactivating each of the secondary and primary auditory cortical areas, and selectively targeting feedback projections (while leaving feedforward processing intact) during behaviour using spatially and temporally precise optogenetic neural silencing.</gtr:technicalSummary><gtr:potentialImpactText>Hearing loss affects more than 300 million people world-wide and as such is the most common sensory disorder. Even people with mild hearing loss consider understanding speech in the presence of competing sounds to be a challenge. Hearing loss has profound social and economic implications, which will only be compounded by an ageing population and an increasing prevalence of hearing loss in younger listeners. Currently, hearing aids and cochlear implants can compensate (albeit poorly) for hearing loss at the level of the ear. While a degraded signal reaching the brain (as in the case of hearing loss) will have a clear negative impact upon listening in complex situations problems successfully engaging neural mechanisms to segregate or select a source from a mixture will also cause difficulties in listening in noise. Even normal hearing listeners differ in their ability to process complex sounds and a significant proportion of this variability is explained by the ability of listeners to employ auditory attention effectively. However, very little is known about how central mechanisms contribute to listening in healthy adults, let alone in those with impaired hearing or in ageing listeners for whom declining central processing and/or cognitive function may additionally contribute. Impaired central mechanisms are known to underlie perceptual impairments in children with Central Auditory Processing Disorder (CAPD). 5% of children presenting at Audiological clinics receive a diagnosis of CAPD, characterised by a normal audiogram but impaired performance in complex listening tasks such as sound localisation or speech-in-noise. In some cases CAPD patients exhibit marked cortical abnormalities highlighting the importance of a better understanding of the mechanism by which auditory cortex facilitates complex listening.

A better knowledge of the principles used by the brain to separate and select sources will provide knowledge for engineers working on signal processing devices for auditory prosthesis including hearing aids, cochlear and mid-brain implants. Currently technology exists to equip implants with multiple microphone arrays that should in theory facilitate better source separation and selection, but their utilization is limited by the requirement to 'steer' such devices. Our work could lead to the development of brain computer interfaces capable of detecting cortical signatures associated with an attended auditory object. Such signals could potentially be 'read-out' non-invasively and be used in conjunction with multi-microphone arrays for source steering. Furthermore, understanding how the brain processes sounds is pivotal for designing and optimizing devices that are biologically compatible at a computational level.

Technology beneficiaries will include communications companies and electrical engineers for whom a better understanding of how to extract one signal from many may lead to developments in machine-listening. In particular, biologically inspired signal decomposition techniques could find broader applications in fields of science and engineering where multiple signal sources must be identified from a single input signal. 

We are keen to promote our science to the public: the PI actively participates in public engagement work to communicate our science to a variety of audiances and will encourage the PDR to do so.

We will be able to deliver impact within the duration of the grant in the form of disseminating information to academic beneficiaries and to lay audiences. Our impact upon telecommunications, hearing prosthesis manufacturers and clinical beneficiaries will be on a longer timescale but the Ear Institute offers the appropriate links with industry to be able to do so when appropriate. UCL has a proactive and effective media office which we will work with in order to ensure the impact of our work beyond the academic community.</gtr:potentialImpactText><gtr:fund><gtr:end>2019-03-31</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2016-04-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>527364</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Cafe Scientific</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>5D4FFE32-61CE-400C-999A-29011285E6AA</gtr:id><gtr:impact>Cafe Scientific at the Royal Society. Event was full to capacity with a large audience of interested members of the public and hearing impaired listeners.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Cafe Scientific</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>D9D41AE7-642A-482D-A988-94029B2E5A78</gtr:id><gtr:impact>Cafe Scientific as part of Manchester Science festival.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>School visit ( Dr Challoner' High School)</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>C1C09741-2D3C-4D48-B4D7-A60E182091F1</gtr:id><gtr:impact>Cafe Scientific as part of Brain awareness week.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Schools talks, Summer Science Exhibition</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>8E91B578-AB87-40D3-B91E-14F6B6709DD6</gtr:id><gtr:impact>Delivered 5 talks as part of the Royal Society Summer Science Exhibition, forming one of the three sets of talks that are run for school groups to attend during their visit. Each talk was full to capacity (60 people).</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>BBC documentary</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>41152A6B-A574-4A2A-BEED-4B9040F7F1C8</gtr:id><gtr:impact>Participated in the making of a BBC4 documentary on sound &amp;quot;Soundwaves: the symphony of physics&amp;quot;. Developed demos, participated in filming both performing demos and being interviewed about hearing. Broadcast in March 2017.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.bbc.co.uk/programmes/b08h5gk8</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>This grant was only started 9 months ago. The purpose of this grant is to understand how listening to one sound in a mixture shapes activity in auditory cortex. To allow us to observe and manipute neural activity we must perform experiments in animal models and do the first stage of this award has been developing and training a speech identification task that our animal model can perform. We are shortly moving into the next phase where we will ask how changing the parameters of this task (for example listening to a single voice versus listening to a mixture of two voices) alters neural activity in auditory cortex.</gtr:description><gtr:exploitationPathways>The paradigm has already been adapted by other labs (with our assistance).</gtr:exploitationPathways><gtr:id>5737338E-517C-41DA-9A21-B7DFF34F1CC8</gtr:id><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Healthcare</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">BB/N001818/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>E793F7FE-614C-4A45-83A0-BE79B172092C</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal &amp; human physiology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>790AD28C-6380-4025-83C2-6881B93C4602</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal behaviour</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>F439A20B-A9B0-4A68-B703-7F6AE7570E39</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Systems neuroscience</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>