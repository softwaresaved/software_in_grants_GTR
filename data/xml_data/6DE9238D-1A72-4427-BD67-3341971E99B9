<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/5E2B04DD-4A03-45ED-9892-61C5CCB8AC68"><gtr:id>5E2B04DD-4A03-45ED-9892-61C5CCB8AC68</gtr:id><gtr:name>Newcastle University</gtr:name><gtr:department>Institute of Neuroscience</gtr:department><gtr:address><gtr:line1>1 Park Terrace</gtr:line1><gtr:line4>Newcastle Upon Tyne</gtr:line4><gtr:line5>Tyne and Wear</gtr:line5><gtr:postCode>NE1 7RU</gtr:postCode><gtr:region>North East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/5E2B04DD-4A03-45ED-9892-61C5CCB8AC68"><gtr:id>5E2B04DD-4A03-45ED-9892-61C5CCB8AC68</gtr:id><gtr:name>Newcastle University</gtr:name><gtr:address><gtr:line1>1 Park Terrace</gtr:line1><gtr:line4>Newcastle Upon Tyne</gtr:line4><gtr:line5>Tyne and Wear</gtr:line5><gtr:postCode>NE1 7RU</gtr:postCode><gtr:region>North East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/4C673EA0-1929-4292-BF5E-04D3EE56CC78"><gtr:id>4C673EA0-1929-4292-BF5E-04D3EE56CC78</gtr:id><gtr:firstName>Bruno</gtr:firstName><gtr:surname>Rossion</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/2CE12B14-E198-4CF5-9EB9-E2BA443459D5"><gtr:id>2CE12B14-E198-4CF5-9EB9-E2BA443459D5</gtr:id><gtr:firstName>Quoc</gtr:firstName><gtr:otherNames>Chi</gtr:otherNames><gtr:surname>Vuong</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=ES%2FJ009075%2F1"><gtr:id>6DE9238D-1A72-4427-BD67-3341971E99B9</gtr:id><gtr:title>A neuropsychological approach to dissect face perception and perceptual expertise</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>ES/J009075/1</gtr:grantReference><gtr:abstractText>&lt;p>Recognising faces is at the heart of human social interactions. By adulthood, people are very good at extracting identity, sex, race, emotions, and social signals from faces. Therefore, impairments to this ability can drastically reduce their quality of life.&lt;/p>

&lt;p>The aim of this project is to investigate the neural mechanisms underlying people?s ability to process faces and how these mechanisms adapt with experience. The approach is to test whether individuals with prosopagnosia can acquire expertise of novel non-face objects through training. These individuals had head trauma during adulthood that lead to damage in specific brain regions. These regions are thought to process only faces and no other object categories. However, these regions may be more generally involved in processing object categories for which people have expertise (eg, bird experts). In addition to neurological case studies, volunteers will also go through the training. Their brain will be scanned using magnetic resonance imaging to determine how the putative face-specific regions change over the course of training. Overall, the results will have an impact on clinical populations which can result in face recognition deficits, such as Alzheimer?s disease, stroke patients, and developmental disorders that affect social interactions (eg, Autism).&lt;/p></gtr:abstractText><gtr:potentialImpactText>Our proposed research has an impact for psychologists, neuropsychologists, social scientists, clinicians and therapists, and will have broad appeal to the public. Here we summarise the social and health impact of the proposed research.

Social and Public Impact
First and foremost, our proposed research will directly benefit the individuals with acquired pure prosopagnosia who volunteer their time and energy to participate in our study. They are acutely aware of their deficit and must cope with it on a daily basis. The findings will help them understand the deficit while at the same time allowing them to contribute to science. Our quantitative test batteries may also help to identify areas of strengths and weaknesses in their perceptual abilities. We can therefore target their weaknesses or capitalise on their strengths to individually help them cope with their face recognition deficits. Furthermore, our research will have a positive impact on family, friends and the general public, as they will also have a better understanding and awareness of perceptual face recognition deficit. For instance, our results will highlight that poor social interactions can be due to perceptual deficits rather than due to deficits in social and communication skills.

Second, our proposed research will have an impact on more common and potentially more devastating clinical conditions. Although cases of acquired prosopagnosia are relatively rare, the outcomes of our proposed research will help in other clinical domains. For example, strokes or dementia can lead to profound visual deficits in both face and object recognition. There is also growing evidence for a form of congenital or developmental prosopagnosia, which is a life-long impairment in face recognition that is not caused by brain damage. These cases of congenital prosopagnosia would be highly prevalent in the population (about 2%). Even though the two forms of prosopagnosia are likely to be qualitatively different, the outcomes of this proposed research can help develop better assessment tools and rehabilitation programs for these people. Lastly, there are also developmental disorders, such as Autism, that can lead to abnormal face recognition and social interaction skills.

Health Impact
Finally, our proposed research will have an impact on clinicians and therapists. Through them, our research outcomes can have an impact on national health in the long term. Our scientific objectives are to understand proficient face recognition at the theoretical, behavioural and neural level. The outcome of the proposed research may also show brain plasticity even for the damaged adult brain. Thus, this holistic understanding of proficient face recognition will allow clinicians and therapists to develop more effective therapies targeted for individual patients. Furthermore, our proposed research can help them develop better rehabilitative programs and better neuropsychological assessment tools. 

Overall, by testing rare cases of acquired pure prosopagnosia, this collaborative grant is an excellent opportunity to put the UK in the forefront of a highly prominent and socially important topic in psychology, neuropsychology, and social/cognitive neuroscience.</gtr:potentialImpactText><gtr:fund><gtr:end>2016-04-30</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/924BE15C-91F2-4AAD-941A-3F338324B6AE"><gtr:id>924BE15C-91F2-4AAD-941A-3F338324B6AE</gtr:id><gtr:name>ESRC</gtr:name></gtr:funder><gtr:start>2012-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>311895</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The main aim of the research grant is to investigate the changes that occur in the adult human brain as they acquire expertise with artificial (i.e., unfamiliar) objects through extensive training. We planned to test healthy participants and patients who have prosopagnosia, which is an inability to recognize faces.

Our main findings are as follows:

1. We created artificial objects in such a way that they can resemble faces (facelike) or not (nonfacelike). We have shown that facelikeness can influence how well healthy adult volunteers can recognize these objects. These volunteers have no prior experience with these objects. This finding suggests that volunteers are using a &amp;quot;face template&amp;quot; to help them recognize unfamiliar objects that resemble faces.

2. We trained adult volunteers to recognize a large number of the artificial objects and recorded their brain responses before and after training using electroencephalography (EEG). This method measures electrical activity on the scalp and can be used to measure the extent to which the brain rapidly and automatically recognizes objects. One group (N = 15) was trained with facelike objects and the other group (N = 15) was trained with nonfacelike objects. Both groups were able to quickly recognize the objects by the end of the 3-week training period. We found that for the facelike group, there were behavioural and neural changes following training. By comparison, the nonfacelike group did not show any changes. This finding suggests that volunteers use their &amp;quot;face template&amp;quot; to enhance the development of expertise for a new object category during visual learning.

Our main development are as follows:

3. We created a new set of artificial objects in a 3D modelling software that allows researchers to create a very large number of objects in a very systematic way. Importantly, researchers can systematically change a number of objects features that may be important for visual recognition (e.g., the number of parts, the shape of these parts, etc.). We provide programs to facilitate stimulus generations and to measure different aspects of the final set of objects created (e.g., how visually similar objects in the set are to each other). The 3D models and program will be made freely available to the research community. This is an important development because this is the first 3D object set that allows researchers to efficiently create a large number of objects in a systematic way to test different theories of face and object recognition.

4. We developed a new training program that builds on and extends previous programs. For example, our program uses a larger variety of training tasks to engage the volunteers, we show objects from many different viewpoints, and we test for a much longer period (3-weeks, ~24-28 hours). Our EEG results demonstrates that this training program is effective. This development is important because we wanted to create a laboratory-based training program that was more similar to real-world learning.

5. We adapted our EEG paradigm for functional magnetic resonance imaging (fMRI). We have been able to replicate some of the EEG results with faces using fMRI with a large number of adult volunteers (N = 25). We have piloted our training paradigm (N = 6), and currently analyzing the data. Through our collaborations, we are also testing different variations of the fMRI paradigms (York University, Canada; University of Maastricht). This is an important development because the paradigm provides a much higher signal-to-noise ratio than typical fMRI paradigms, and fMRI allows us to find which parts of the brain respond to our objects or which parts change following training. 

6. Related to (5), we developed new frequency analyses of the data collected with our new fMRI paradigm. We will make these new analysis techniques freely available to the research community.</gtr:description><gtr:exploitationPathways>Our EEG results with healthy participants provide strong justification to test prosopagnosic volunteers who may not be able to develop expertise for any new object domain due to their brain damage.

Our new artificial object set can be used to address what are the important features for face and object recognition.

Our new fMRI paradigm can be used to test different issues in visual face and object recognition.</gtr:exploitationPathways><gtr:id>A7758CDB-61D1-4219-9B42-D0E9C0EBFA3C</gtr:id><gtr:sectors><gtr:sector>Other</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>We have developed and validated a new 3D stimulus set of novel objects. We can systematically manipulate the overall 3D shape of each object, its part and its surface texture so that the similarity of the set of these novel objects can be precisely controlled. This stimulus set will allow researchers to easily create a large set objects in a systematic and controlled manner to test different theories of face and object recognition, and different theories of visual learning. We have been using the stimulus set in our learning study to see how volunteers, including those with brain lesions, can learn to individuate each stimulus (e.g., by learning its unique name). As part of this data set, we have included scripts to facilitate and automate some of the stimulus generation process (in Studio Max and in Matlab). The database is also on Reshare (see URL below).

Part of this work has been presented in abstract form (Willenbockel V, Lochy A, Laguesse R, Dryden A R, Rossion B, Vuong Q C, 2014, A parametric three-dimensional stimulus set controlled for perceptual similarity Perception 43 ECVP Abstract Supplement, page 167). The paper is now accepted: Vuong QC, Willenbockel V, Zimmermann FGS, Lochy A, Laguesse R, Dryden A, Rossion R (2017). Facelikeness matters: A parametric multipart object set to understand the role of spatial configuration in visual recognition. Visual Cognition.</gtr:description><gtr:id>13735A85-6BDE-40A9-849C-92B00F67B4AA</gtr:id><gtr:impact>N/A</gtr:impact><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>Novel parametric 3D objects</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://reshare.ukdataservice.ac.uk/852397/</gtr:url><gtr:yearFirstProvided>2014</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs><gtr:researchMaterialOutput><gtr:description>We have implemented two physical measures of similarity both of which show a high correlation with human similarity ratings. These measures are implemented in Matlab as part Vuong et al. (2017; see URL and DOI).</gtr:description><gtr:id>2843AC91-0886-4DE0-8ADE-E9188E595771</gtr:id><gtr:impact>N/A</gtr:impact><gtr:providedToOthers>false</gtr:providedToOthers><gtr:title>Perceptually validated similarity measures</gtr:title><gtr:type>Model of mechanisms or symptoms - human</gtr:type><gtr:url>http://reshare.ukdataservice.ac.uk/852397/</gtr:url></gtr:researchMaterialOutput></gtr:researchMaterialOutputs><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/ABC36494-785B-49E5-8E23-3BEF4BC09B4D"><gtr:id>ABC36494-785B-49E5-8E23-3BEF4BC09B4D</gtr:id><gtr:title>Facelikeness matters: A parametric multipart object set to understand the role of spatial configuration in visual recognition</gtr:title><gtr:parentPublicationTitle>Visual Cognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/3e057f87f7337cc680e821c12d78882d"><gtr:id>3e057f87f7337cc680e821c12d78882d</gtr:id><gtr:otherNames>Vuong Q</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">ES/J009075/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>F439A20B-A9B0-4A68-B703-7F6AE7570E39</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Systems neuroscience</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>