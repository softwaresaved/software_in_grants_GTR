<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/818CD6C9-61EE-41F2-9F37-0C7A8F43E25D"><gtr:id>818CD6C9-61EE-41F2-9F37-0C7A8F43E25D</gtr:id><gtr:name>University of Birmingham</gtr:name><gtr:department>Electronic, Electrical and Computer Eng</gtr:department><gtr:address><gtr:line1>Edgbaston Park Road</gtr:line1><gtr:line2>Edgbaston</gtr:line2><gtr:postCode>B15 2TT</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/818CD6C9-61EE-41F2-9F37-0C7A8F43E25D"><gtr:id>818CD6C9-61EE-41F2-9F37-0C7A8F43E25D</gtr:id><gtr:name>University of Birmingham</gtr:name><gtr:address><gtr:line1>Edgbaston Park Road</gtr:line1><gtr:line2>Edgbaston</gtr:line2><gtr:postCode>B15 2TT</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/CF92F085-6B6A-4A55-BEA8-033EF5469D54"><gtr:id>CF92F085-6B6A-4A55-BEA8-033EF5469D54</gtr:id><gtr:firstName>Peter</gtr:firstName><gtr:surname>Jancovic</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FD033659%2F1"><gtr:id>C12F4236-40AC-4DFC-9033-DFA568FD3EE7</gtr:id><gtr:title>Feature-Combination for Noise Robust Speech Pattern Processing</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/D033659/1</gtr:grantReference><gtr:abstractText>Current systems for automatic speech recognition by computer can obtain an acceptable performance in carefully controlled environments. However, in real-world situations, speech signal is usually contaminated by an acoustic background environmental noise. While humans show strong robustness to noise, the performance of current automatic speech recognition systems degrades rapidly, even for a simple task such as digit recognition.Speech signal may be represented by multiple features, which may be obtained by using different sources of information or different processing techniques on a specific source. In a given set of features, there may be some features corrupted by noise. Ideally, the features dominated by noise should be excluded from recognition. To achieve this, a-priori knowledge about the identity of the noisy features is required. Unfortunately locating the corrupted features itself can be a difficult task, if there is no prior information about the noise. Thus, to exploit the potential of the unaffected features, we face the problem of how to combine the features when assuming no knowledge about the noise.In our previous work, we developed a feature-combination model that attempts to release the need for identification of the noisy features. A key result of previous studies is that, when the noise has a partial frequency/temporal character, this model using no information about noisy features has achieved similar recognition performance as a model using full a-priori knowledge about the noisy features.Our previous study dealt with a general problem of combination of features in order to eliminate the effect of noisy features under the assumption of no knowledge about the noise. This provides a good base for the development of more powerful feature-combination models capable of exploiting the inherent properties of speech signals. Our proposed research aims to develop feature-combination models that incorporate: (1) the fact that in a wide-band noisy environment, the valleys of spectrum are easily corrupted by noise while peaks are often affected little; (2) any information about reliability of features, which may often be available by exploiting properties of speech signals. Moreover, the proposed investigation on modelling of speech signals based on modelling the filter and source information separately can be incorporated into the feature-combination models. Such models will be tailored for speech pattern processing and thus should provide an improved recognition performance. Our final goal is to demonstrate competitive performance in speech and speaker recognition; we aim to achieve significant performance improvements on standard datasets (TIDIGITS, TIMIT, Resource Management, and Switchboard, respectively).</gtr:abstractText><gtr:fund><gtr:end>2008-08-01</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2006-05-02</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>116442</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/B9CC538F-322B-41B9-9E56-213E6BF2DA7D"><gtr:id>B9CC538F-322B-41B9-9E56-213E6BF2DA7D</gtr:id><gtr:title>Fast Algorithm for Calculation of the Union-Based Probability</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Audio, Speech and Language Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/443ecc9f329262723babdef7cb2f5ae5"><gtr:id>443ecc9f329262723babdef7cb2f5ae5</gtr:id><gtr:otherNames>Jancovic P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/89FC5EDB-FF17-4764-970A-C1380EF9630F"><gtr:id>89FC5EDB-FF17-4764-970A-C1380EF9630F</gtr:id><gtr:title>Improving automatic phoneme alignment under noisy conditions by incorporating spectral voicing information</gtr:title><gtr:parentPublicationTitle>Electronics Letters</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/f8b18a4d15c35cf3b76f8fc55b89219b"><gtr:id>f8b18a4d15c35cf3b76f8fc55b89219b</gtr:id><gtr:otherNames>Janc?ovic? P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/0801A846-1934-4390-A544-514922DA9282"><gtr:id>0801A846-1934-4390-A544-514922DA9282</gtr:id><gtr:title>ICA-Based MAP Algorithm for Speech Signal Enhancement</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/323327f946161a4d54706803fcf93469"><gtr:id>323327f946161a4d54706803fcf93469</gtr:id><gtr:otherNames>Zou X</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:isbn>1-4244-0727-3</gtr:isbn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/B6832B68-CA58-4F04-BC59-212B7147B94E"><gtr:id>B6832B68-CA58-4F04-BC59-212B7147B94E</gtr:id><gtr:title>Separation of Harmonic and Speech Signals using Sinusoidal Modeling</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/443ecc9f329262723babdef7cb2f5ae5"><gtr:id>443ecc9f329262723babdef7cb2f5ae5</gtr:id><gtr:otherNames>Jancovic P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:isbn>978-1-4244-1618-9</gtr:isbn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/35BBD293-AC1A-4955-9CBE-071149A71B17"><gtr:id>35BBD293-AC1A-4955-9CBE-071149A71B17</gtr:id><gtr:title>Estimation of Voicing-Character of Speech Spectra Based on Spectral Shape</gtr:title><gtr:parentPublicationTitle>IEEE Signal Processing Letters</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/443ecc9f329262723babdef7cb2f5ae5"><gtr:id>443ecc9f329262723babdef7cb2f5ae5</gtr:id><gtr:otherNames>Jancovic P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/8617D0E6-7BF3-4E73-8045-E455851B2BDF"><gtr:id>8617D0E6-7BF3-4E73-8045-E455851B2BDF</gtr:id><gtr:title>Speech Signal Enhancement Based on MAP Algorithm in the ICA Space</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Signal Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/323327f946161a4d54706803fcf93469"><gtr:id>323327f946161a4d54706803fcf93469</gtr:id><gtr:otherNames>Zou X</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/E2030E02-B38D-42DD-8376-9DE5D1F89447"><gtr:id>E2030E02-B38D-42DD-8376-9DE5D1F89447</gtr:id><gtr:title>Incorporating the voicing information into HMM-based automatic speech recognition in noisy environments</gtr:title><gtr:parentPublicationTitle>Speech Communication</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/443ecc9f329262723babdef7cb2f5ae5"><gtr:id>443ecc9f329262723babdef7cb2f5ae5</gtr:id><gtr:otherNames>Jancovic P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/D033659/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>699D8438-2A43-4BCF-B1A4-6240ED82CEEE</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Human Communication in ICT</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>