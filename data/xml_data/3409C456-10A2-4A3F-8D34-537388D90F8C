<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/A8967420-49D3-4509-9912-25FB3EC75B74"><gtr:id>A8967420-49D3-4509-9912-25FB3EC75B74</gtr:id><gtr:name>University of Sussex</gtr:name><gtr:department>Sch of Engineering and Informatics</gtr:department><gtr:address><gtr:line1>The Administration</gtr:line1><gtr:line2>Sussex House</gtr:line2><gtr:line3>Falmer</gtr:line3><gtr:line4>Brighton</gtr:line4><gtr:line5>East Sussex</gtr:line5><gtr:postCode>BN1 9RH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/A8967420-49D3-4509-9912-25FB3EC75B74"><gtr:id>A8967420-49D3-4509-9912-25FB3EC75B74</gtr:id><gtr:name>University of Sussex</gtr:name><gtr:address><gtr:line1>The Administration</gtr:line1><gtr:line2>Sussex House</gtr:line2><gtr:line3>Falmer</gtr:line3><gtr:line4>Brighton</gtr:line4><gtr:line5>East Sussex</gtr:line5><gtr:postCode>BN1 9RH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/BE45C528-D30C-4985-BC68-4325B02231C7"><gtr:id>BE45C528-D30C-4985-BC68-4325B02231C7</gtr:id><gtr:firstName>Leon</gtr:firstName><gtr:surname>Lagnado</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/B55CB73A-CEBB-4469-B052-B3761199AE0B"><gtr:id>B55CB73A-CEBB-4469-B052-B3761199AE0B</gtr:id><gtr:firstName>Christopher Laurie</gtr:firstName><gtr:surname>Buckley</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=BB%2FP022197%2F1"><gtr:id>3409C456-10A2-4A3F-8D34-537388D90F8C</gtr:id><gtr:title>Distributed neural processing of self-generated visual input in a vertebrate brain</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/P022197/1</gtr:grantReference><gtr:abstractText>Most of what we do on a day-to-day basis involves the ongoing and fluid coordination between our senses and our actions. For example, making a cup of tea involves processing a constant stream of visual and tactile (touch) information to continuously correct how we move our muscles in order to avoid spilling milk or breaking a mug. Our brains coordinate this flow of sensory to motor information effortlessly, yet it is an ability that modern engineering still cannot rival; think of the clumsy robots in this year's DARPA Robotics Challenge. The ability to coordinate sensory input and motor actions is also often impaired in diseases like Parkinson's and dyspraxia. Understanding this ability is therefore not only a central goal of modern neuroscience but also one that promises to deliver advances for engineering and facilitate the treatment of disease.

Over the last century, neuroscience research has revealed that areas across the brain are required to process sensory and motor information during active behaviours. These include sensory and motor systems but also areas such as the cerebellum and the basal ganglia. While a partial understanding of the underlying processes in specific circuits has been achieved, a full understanding would ideally require recordings of the neural activity from across the brain in a behaving animal. This type of experiment has been impossible in the past for two reasons: 1. Neural recording techniques require a great degree of stability between recording devices and neural tissue; thus most experiments involve heavily restrained, or anesthetized, animals, which prevents meaningful brain/environment interactions. 2. Typical brain recordings have been limited to either small numbers neurons at cellular resolutions or indirect recordings from large areas of brain tissue at low spatial and/or temporal resolution. To address these challenges will combine advanced techniques in experimental and computational neuroscience. First, a virtual reality for a swimming larval zebrafish; this will allow us to record from a non-moving brain but allow fictive behaviour. Second, light-sheet microscopy, a technique that can simultaneously image 10000's of neurons from across the zebrafish brain. Third, distributed computing techniques, which will enable us to analyse the enormous data sets (upto a terabyte per trial) acquired from these experiments.

We will use these tools to address three fundamental questions about brain function in behaving animals. First, when animals actively engage the world the brain receives two types of sensory input: Sensory input caused by changes in the external world, e.g. the optic flow experienced by a fish as water sweeps past its retina, and sensory input that is a consequence of their own actions, e.g. the optic flow experienced by the fish that results from its own swimming. These two types of inputs convey different types of information but arrive together on the retina. Thus a central question we will ask is what are the brain-wide circuits that allow the fish to distinguish between them. Second, animals readily adapt their behaviour when the sensory inputs caused by their own actions do not meet their expectations. For example, fish modulate the strength of swimming when changes in water viscosity cause a mismatch between the actual and expected consequences of their swimming, i.e., when their swimming does not propel them as far as they expect. We will ask what the distributed neural circuits are that allow fish to detect these mismatch errors. We will combine our results to produce a biologically plausible model of closed-loop control in an actively swimming fish that reproduces experimental observations and could be used to inspire robotic control systems.

This project will develop new techniques to record and analyse large neural datasets and provide unique insight into the distributed and dynamic nature of brain function necessary for successful active behaviour.</gtr:abstractText><gtr:technicalSummary>During movement sensory input and motor output are bound in a closed-loop: motor actions shape sensory input and sensory inputs inform future motor commands. Studies over the last century have revealed that the neural circuits processing this closed-loop flow of information are widely distributed, i.e., including sensory and motor systems and intervening areas such as the cerebellum and basal ganglia. In this project, to characterise these brain-wide neural circuits, we will combine: 1. A swimming virtual reality (VR) environment for larval zebrafish. 2. Light-sheet microscopy to image neurons across the brain. 3. Distributed computing techniques to analyse the large data sets produced by this setup with established (PCA, ICA) and leading edge analysis techniques (e.g. Granger causality).

We will address three core questions that emerge from a consideration of closed-loop processing. Q1. What are the distributed neural circuits that allow fish to distinguish between the visual consequences of voluntary action (reafferent input) and visual input originating in the external environment (exafferent input). Q2. What are the distributed neural circuits that allow fish to detect when visual consequences of motor action (reafferent input) do not meet expectations?, indicating a failure to control their surrounding environment. Q3. Lastly how do fish distinguish between mismatch errors caused by external environment (exafferent input; as in Q1) and those caused by a failure to control their surrounding environment (as in Q2). We will construct, and test, a computational model of the observed circuit dynamics and computations.

This investigation will develop new algorithms to identify circuits in large neural datasets, elucidate the biological basis of closed-loop processing to inspire robotic control systems, and identify aspects of brain function that are contingent on closed-loop dynamics and thus may have been overlooked in traditional open-loop approaches.</gtr:technicalSummary><gtr:potentialImpactText>In addition to the academic beneficiaries of this work it will impact on a) the public health sector, b) the commercial private sector, c) public communication and d) the wider academic community, as described below.

Public health sector
Zebrafish are becoming an important model system for the study of brain dysfunction and, at the same time, are becoming a leading systems for rapidly screening pharmaceutical compounds which target specific behavioural deficits. Our setup has the potential to enhance screening techniques by identifying higher order (brain-wide) functional (during behaviour) effects of drugs. It will promote a more holistic understanding of sensorimotor coordination, which will allow a more refined characterization of the deficits caused by diseases like dyspraxia, Parkinson's and Huntington's and potentially impact on the development of high end prosthetics.

The private commercial sector
Over the last decade there has been a significant rise in the commercialisation of autonomous robots that work in dynamic real-world environments. Understanding the neural circuits that allow animals survive and adapt during active behaviours is potentially a richer source of ideas than more traditional open-loop approaches for this application. Our research group, the Centre for Computational Neuroscience and Robotics (CCNR), has strong ties to the robotics community and industry and is well placed to exploit this avenue.

Big data approaches are increasingly seen as a central to scientific projects but also have significant socio-economic relevance. The development of a connectivity analysis toolbox for 'big data' is relevant for many domains. For example, these techniques can be used to understand potential relationships between measures of online (social media) discussion and offline events. In this context we have had expressions of interest from CASM Consulting LLP.

Public communication
Both LL and CLB are actively involved in outreach activities. We will present 
the core science, and more generally promote STEM subjects, at school 6th forms, contribute to public meetings, such as Cafe Scientifique and the Brighton Science Festival.

Over the last few decades there has been an increasing tendency to take a narrowly neurocentric view of behaviour. For example, in Francis Crick's book 'An astonishing hypothesis' he suggests that &amp;quot;your joys and your sorrows, your memories and your ambitions, your sense of personal identity and free will, are in fact no more than the behaviour of a vast assembly of nerve cells and their associated Molecules&amp;quot;. This idea contrasts with a movement in the cognitive sciences which has long argued that understanding behaviours requires an explicit appreciation of brain/body/environment interactions (e.g. see 'Out of our heads: Why you are not just your brain' by Alva Noe). The goals of this project resonates with, and extends, this latter view by suggesting that not only behaviour, but brain dynamics, are contingent on an appreciation of brain-environment interactions. We feel these broad ideas will be of significant interest to the public, and have potential implications for public health, e.g., promoting exercise and rich environments for mental health, and we will disseminate them through public talks, organised discussions as well as popular science articles.

The wider academic community
The advent of VR approaches in neuroscience provides a unique opportunity to revisit our understanding of the biological basis of sensorimotor control. The achieve impact in this area we intend to organise a broad workshop between experimental neuroscientists working with VR approaches in mice and fish and sensorimotor theorists from behavioural neuroscience and robotics. The goal of the workshop will be to allow those working with VR to contextualise their results in terms modern sensorimotor theory and to inspire new algorithm and mechanisms for theorists and engineers.</gtr:potentialImpactText><gtr:fund><gtr:end>2020-09-30</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2017-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>434293</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">BB/P022197/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>4A2A69ED-37ED-4980-91A7-E54B4F6A9BC6</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal organisms</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>F439A20B-A9B0-4A68-B703-7F6AE7570E39</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Systems neuroscience</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>