<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/8319F78A-DCBD-49F6-BE00-78E1CD75CDA9"><gtr:id>8319F78A-DCBD-49F6-BE00-78E1CD75CDA9</gtr:id><gtr:name>University of York</gtr:name><gtr:department>Electronics</gtr:department><gtr:address><gtr:line1>Heslington</gtr:line1><gtr:line4>York</gtr:line4><gtr:line5>North Yorkshire</gtr:line5><gtr:postCode>YO10 5DD</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/8319F78A-DCBD-49F6-BE00-78E1CD75CDA9"><gtr:id>8319F78A-DCBD-49F6-BE00-78E1CD75CDA9</gtr:id><gtr:name>University of York</gtr:name><gtr:address><gtr:line1>Heslington</gtr:line1><gtr:line4>York</gtr:line4><gtr:line5>North Yorkshire</gtr:line5><gtr:postCode>YO10 5DD</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/CB8D8CC3-4C12-41DE-B5E1-C13656BB68BB"><gtr:id>CB8D8CC3-4C12-41DE-B5E1-C13656BB68BB</gtr:id><gtr:firstName>Damian</gtr:firstName><gtr:surname>Murphy</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/A028B856-3C66-4CD6-B689-444640BCEE3B"><gtr:id>A028B856-3C66-4CD6-B689-444640BCEE3B</gtr:id><gtr:firstName>Judith</gtr:firstName><gtr:otherNames>Sara</gtr:otherNames><gtr:surname>Brereton</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=AH%2FH036938%2F1"><gtr:id>8059B253-BA6B-4B44-A0F1-296D0FF2347F</gtr:id><gtr:title>The Virtual Acoustics and Auralization Database</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>AH/H036938/1</gtr:grantReference><gtr:abstractText>The buildings we inhabit everyday affect us all in terms of how we communicate, project our voice, listen to our environment, and respond to excessive noise. The sound of the built environment and good acoustic design is critical in modern architectural practice and this is in part based on a clear understanding of what has gone before, hence the fascination with, for example, the great concert halls and opera houses of Europe and their influence on modern design practices. More recently there has also been interest in the research and preservation of the acoustics of heritage sites which presents additional opportunities for both understanding and interpretation of the past as well as developing new audiences for work of this nature through novel virtual reality style interaction. Acoustic data also provides additional opportunities to inform issues relating to preservation and measurement of degradation or change over time. A key example being the destruction by fire of the Gran Teatro La Fenice in Venice in 1996, and its subsequent restoration, where acoustic measurements taken just prior to the fire played a key role in the acoustic redesign. The main application for this data however is in music production, where the acoustic effects of real spaces, played back around a listener or audience over many loudspeakers presents exciting, dramatic and highly realistic acoustic environments in which recorded musical works can be contextualised.\n\nDevelopments in measuring the acoustics of concert halls and opera houses have resulted in standardised methods of impulse response capture for a wide variety of auralization applications. The impulse response is the acoustic fingerprint for a given space and uniquely defines its acoustic characteristics for particular sound source and listener positions. From these measurements objective acoustic parameters, as used in the design process can be determined. The result can also be used to create a virtual acoustic representation of the space so that a listener can experience the same aural sensations remotely as if they were actually there - this is what auralization is, a term derived as the audio equivalent to visualisation. These techniques are now commonly used in both architectural acoustics and in the field of acoustic archaeology (archeoacoustics). Measurements of existing real environments can be further extended by analogous techniques employed for virtual sites that only exist as part of a 3D computer model - these latter techniques are highly applicable in the field of acoustic archaeology where an existing site may have little resemblance to how it looked or sounded at the height of its use.\n\nResearchers at York currently have extensive acoustic survey data for 12 actual sites and 2 3D computer models. This work was initiated through an AHRB/ACE Science/Heritage Fellowship in 2004 but to date only a small part of this work has been made more widely available. The aim of this project is to produce a sustainable online repository for this data and a more general resource for research in virtual acoustics. This will consist of a database of high-resolution acoustic impulse responses for sites across and beyond the UK, starting with the 14 that have currently already been completed. These measurements will be supported with software to enable third parties to conduct their own acoustic surveys, upload the impulse responses obtained and audition the final results using specially recorded anechoic audio material that will also be made available.\n\nThis resource will have significant impact in music production as well as in the fields of architectural/archaeological acoustic studies. There will also be related impact in the field of audio engineering where auralization and its effective delivery to the listener are key issues relating to, for example, the development of interactive entertainment and communication, high definition television, and computer game audio development.</gtr:abstractText><gtr:potentialImpactText>Who will benefit from this research?\n\nThe main beneficiaries for this research will be those computer musicians and composers interested in working with the highest quality or most realistic options for rendering acoustic space. Additional beneficiaries include acoustic consultants working in industry who will be able to use new software, acoustic data and recordings to inform their work with the possibility of demonstrating new or extended auralization techniques for their clients.\nAlso benefitting will be the owners and custodians of the sites themselves. An acoustic snapshot of the space in question will provide a record for posterity which may be of use for future restoration or act as an additional means of measuring degradation or change. This data, if appropriate, may be used in the development of visitor interactives, audio guides or VR representations.\nFinally, the new experiences and enhanced understanding that will result from this work together with the development of new means for interacting with a site through its acoustic representation will ultimately be of benefit to the wider public as the visitors to these sites, and the consumers of the new music and interactive virtual experiences that may well result.\n\nHow will they benefit?\n\nThe outcome of this research will provide computer musicians with an expanded toolset for the capture, exploration and auditioning of acoustic spaces. The developing library of acoustic impulse responses will help to expand creativity through an increased palette of acoustic environments in which musical works might be contextualised.\nFor acoustic consultants and architectural acousticians the additional data, robustly measured and validated can be used to inform current design strategies through a better understanding of existing practice. New software will enable beneficiaries to conduct their own measurement work more effectively and the expanded library of anechoic material will be invaluable in developing new auralization demonstrations.\nSite owners and custodians will have new data available to inform curatorial, building management and environmental decision making. Where the acoustic environment is more critical (e.g. concert halls, performance venues, classrooms, public spaces), the acoustic data will provide an invaluable record of current performance against which possible future changes, planned improvements or natural degradation might be measured.\nAuralization and VR applications, audio guides, or site interactives will demonstrate the potential for new means of engagement and provide another important dimension alongside more usual visual presentations. Hence there is also the potential for developing new audiences for these sites.\nThe public will ultimately benefit from the development of new musical works, the opportunities to listen to and experience important architectural or archaeological spaces in new ways, the potential for new means of visitor understanding and engagement with these sites and through their acoustic preservation for future generations.\n\nWhat will be done to ensure that they benefit?\n\nThis whole project is focused on the wider dissemination of this existing and future work and the valuable resource that is generated as a result. All aspects will be documented and made available online for all potential users to interact with. All new procedures and workflow practices will be tested for efficiency and effective ease of use. To highlight the potential benefits of acoustic simulation for a variety of applications and as a means to explore, audition and interact with acoustic space, a demonstration of walk-through auralization will be prepared and made available for all visitors to the site. We will make use of the University of York press office to announce the launch of the completed website and target potential user groups through</gtr:potentialImpactText><gtr:fund><gtr:end>2011-09-10</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/1291772D-DFCE-493A-AEE7-24F7EEAFE0E9"><gtr:id>1291772D-DFCE-493A-AEE7-24F7EEAFE0E9</gtr:id><gtr:name>AHRC</gtr:name></gtr:funder><gtr:start>2010-03-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>109608</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>York Talks - Sound Design for our Sound Environment</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>0BA2B32B-D660-44C6-B80D-1061FA520DB2</gtr:id><gtr:impact>YorkTalks is the University of York's own TEDx style presentations of key research. This talk resulted in a piece of written work for 'The Conversation' which reached a much wider international audience.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>https://theconversation.com/shaping-up-our-soundscapes-can-improve-our-lives-37175</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Institute of Acoustics: Sound Design for our Sound Environment</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>DD33F775-D005-4276-BDCB-789DE18F0EDA</gtr:id><gtr:impact>I was invited by the Midlands Branch of the Institute of Acoustics to present on my research as part of their ongoing series of professional lectures. The title was - Sound Design for our Sound Environment, University of Derby, 20 Jan. 2016. It prompted discussion and debate, and the invitation arose from the Acoustics team at AECOM, an ongoing collaborative partner for our work in Environmental Acoustics.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>93433</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>AHRC Follow on Fund for Impact and Engagement</gtr:description><gtr:end>2016-12-02</gtr:end><gtr:fundingOrg>Arts &amp; Humanities Research Council (AHRC)</gtr:fundingOrg><gtr:fundingRef>AH/N00356X/1</gtr:fundingRef><gtr:id>6F176917-84B0-436A-BD0E-91BAD2D7B27E</gtr:id><gtr:sector>Public</gtr:sector><gtr:start>2016-02-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>1. The data prepared for the OpenAIR website has been incorporated in the Ableton Live 9 software release under a Creative Commons License. Ableton Live is one of the main software applications used today for music production, recording and audio processing. 
2. The data prepared for the OpenAIR website has been incorporated in the Presonus Studio One v2 software release under a Creative Commons License. Presonus Studio One is a relatively new software application used for music production, recording and audio processing. 
2. The data prepared for the OpenAIR website has been incorporated in the Propellerheads Reason software release under a Creative Commons License. Propellerheads Reason is a relatively new software application used for music production, recording and audio processing.</gtr:description><gtr:firstYearOfImpact>2010</gtr:firstYearOfImpact><gtr:id>08D1753F-0FC6-4B59-87F7-B0E2C83F115D</gtr:id><gtr:impactTypes><gtr:impactType>Cultural,Economic</gtr:impactType></gtr:impactTypes><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software),Education,Culture, Heritage, Museums and Collections</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs><gtr:intellectualPropertyOutput><gtr:description>Database of Acoustic Impulse Response Measurements have been made publicly available via Creative Commons License to a number of audio/computer games companies.</gtr:description><gtr:id>F4E9A681-A6F5-49DC-BC38-A2B5BFD9AFEE</gtr:id><gtr:impact>Database included in Ableton Live 9 Software
Database included in Presonus Studio One v2 Software
Database included in Propellerheads Reason v 8.3 software
Credits on Codemasters Grid Autosports Game for University of York Researchers</gtr:impact><gtr:licensed>Yes</gtr:licensed><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>Open Acoustic Impulse Response Library Database (OpenAIR)</gtr:title><gtr:yearProtectionGranted>2012</gtr:yearProtectionGranted></gtr:intellectualPropertyOutput></gtr:intellectualPropertyOutputs><gtr:keyFindingsOutput><gtr:description>The aim of the project was to source all of our research data and make it accessible via a single, online database. This has been the case. All spaces surveyed up to and including the project are now online and more are added as and when they are completed making this a live resource. Software for Pure Data is available for download to enable convolution using these impulse responses, a walkthrough auralisation video has also been prepared to demonstrate the potential of this work. The site has been accessed and used by individuals working in the creative industries internationally and cited in numerous third party materials.</gtr:description><gtr:exploitationPathways>Our work has succeeded in being made available online to creative communities in music, gaming and heritage. it continues to be a valuable resource, evidenced by the three companies using the database currently, and our collaboration with a third UK gaming company.</gtr:exploitationPathways><gtr:id>F6BEA03F-C591-498F-A67F-7D937CD32A14</gtr:id><gtr:sectors><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software),Education,Leisure Activities, including Sports, Recreation and Tourism,Culture, Heritage, Museums and Collections</gtr:sector></gtr:sectors><gtr:url>http://www.openairlib.net/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>A collection of modelled and measured acoustic data from locations across the world, with data available in a variety of spatial audio formats. Also supported with a set of online anechoic recordings and acoustic analysis tools.</gtr:description><gtr:id>3B975313-803A-479B-BA66-8991DEF4936F</gtr:id><gtr:impact>This work has resulted in one AHRC follow on project, a license to three audio software companies (Ableton, Presonus, Propellerheads) and collaboration with a UK computer games company.</gtr:impact><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>Open Acoustic Impulse Response Library (OpenAIR)</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://www.openairlib.net/</gtr:url><gtr:yearFirstProvided>2010</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>This is a Javascript library, written using the Web Audio Framework to enable OpenAir audio data from our online website (www.openairlib.net) to be used more freely in third party applications. The application receives commands from the client-side classes, performs queries on the OpenAIR internal database, formats the data and returns it to the client classes. Ultimately this library enables OpenAIR acoustic data to be easily integrated into other online applications that use the Web Audio Framework.</gtr:description><gtr:id>A67FEC51-06FB-43D8-B41C-4AAE7C365DFF</gtr:id><gtr:impact>This work was prepared in collaboration with colleagues at BBC R&amp;amp;D, with a view to being used in some of their future online broadcast work.</gtr:impact><gtr:title>OpenAirLib</gtr:title><gtr:type>Webtool/Application</gtr:type><gtr:url>https://github.com/UoYWEAVER/OpenAirLib</gtr:url><gtr:yearFirstProvided>2017</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/C2DC781B-E582-40B7-959E-5E49207EE116"><gtr:id>C2DC781B-E582-40B7-959E-5E49207EE116</gtr:id><gtr:title>OpenAirLib: A JavaScript library for the Acoustics of Spaces</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/7748ccbafd5cd6c98a92b38913d1fe50"><gtr:id>7748ccbafd5cd6c98a92b38913d1fe50</gtr:id><gtr:otherNames>Brown KI</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/3A954BA2-9CAD-498E-AB5A-6662E9219D59"><gtr:id>3A954BA2-9CAD-498E-AB5A-6662E9219D59</gtr:id><gtr:title>OpenAIR: An Interactive Auralization Web Resource and Database</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/d90ce2bef8191309a183a2b343a02b62"><gtr:id>d90ce2bef8191309a183a2b343a02b62</gtr:id><gtr:otherNames>Shelley S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/A31189CA-3F2E-4A5A-9F36-79163CEAD218"><gtr:id>A31189CA-3F2E-4A5A-9F36-79163CEAD218</gtr:id><gtr:title>Acoustic Heritage and Audio Creativity: the Creative Application of Sound in the Representation, Understanding and Experience of Past Environments</gtr:title><gtr:parentPublicationTitle>Internet Archaeology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/c64657023c701c1026a622df56e49660"><gtr:id>c64657023c701c1026a622df56e49660</gtr:id><gtr:otherNames>Murphy D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/9C852C99-31FE-47FC-B746-ADC4491AF19C"><gtr:id>9C852C99-31FE-47FC-B746-ADC4491AF19C</gtr:id><gtr:title>OpenAIR: An Online Auralization Resource with Applications for Game Audio Development</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/d90ce2bef8191309a183a2b343a02b62"><gtr:id>d90ce2bef8191309a183a2b343a02b62</gtr:id><gtr:otherNames>Shelley S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">AH/H036938/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>0AEFDABE-67A4-48B1-9DB4-99393BDE6065</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Music</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>A13304AD-8058-4333-86C7-DB798216A696</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Composition</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>