<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/E4757A6E-7326-472B-9979-B47D77A65446"><gtr:id>E4757A6E-7326-472B-9979-B47D77A65446</gtr:id><gtr:name>Aberystwyth University</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>King Street</gtr:line2><gtr:line3>Ceredigion</gtr:line3><gtr:line4>Aberystwyth</gtr:line4><gtr:line5>Dyfed</gtr:line5><gtr:postCode>SY23 2AX</gtr:postCode><gtr:region>Wales</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/E4757A6E-7326-472B-9979-B47D77A65446"><gtr:id>E4757A6E-7326-472B-9979-B47D77A65446</gtr:id><gtr:name>Aberystwyth University</gtr:name><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>King Street</gtr:line2><gtr:line3>Ceredigion</gtr:line3><gtr:line4>Aberystwyth</gtr:line4><gtr:line5>Dyfed</gtr:line5><gtr:postCode>SY23 2AX</gtr:postCode><gtr:region>Wales</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/2DB25178-A6BA-4651-875C-2195121D6C07"><gtr:id>2DB25178-A6BA-4651-875C-2195121D6C07</gtr:id><gtr:firstName>Hannah</gtr:firstName><gtr:otherNames>Mary</gtr:otherNames><gtr:surname>Dee</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FL017253%2F1"><gtr:id>D84A0E6A-9CDC-4DB4-8E7F-C2A6F203ADA3</gtr:id><gtr:title>Dynamic modelling of plant growth with computer vision</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/L017253/1</gtr:grantReference><gtr:abstractText>Computer vision as a discipline has recently made great progress in the detection and modelling of articulated shapes (for example, human pose detectors). There is, however, very little work in computer vision on the modelling of organisms which change and grow, like plants. This project aims to change that. 

This project will develop computer vision techniques for the modelling, measurement and tracking of plants during growth, working at the level of individual leaves. This is a hard computer vision problem, with application to computational biology, phenomics, and precision agriculture: it involves being able to first find the plants; then detect individual leaves; and then work out what leaves are hidden behind other leaves, and finally to estimate their size and shape of both visible leaves and hidden leaves. 

This will be achieved through the use of computer vision to build up a model of the plant as it grows, recorded in timelapse photographs. This model will encode each leaf's size and shape, and whether that leaf is occluded by or occludes any other leaves. This is the first proposal aiming to treat plants as complex, self-occluding objects whilst modelling from a single viewpoint. From the outputs of the software it will then be possible to derive accurate estimates of biomass, leaf area, and other biologically significant measurements.

As well as the software, this project will publish a dataset which will contain photographs of plants (top down images from a single camera), and for certain images it will also contain a labeling, showing which part of the image (which pixel) corresponds to which leaf. The dataset will also include information from plants that have been dissected, such as the areas of individual leaves, and the weight of the whole plant. This dataset will make a significant contribution towards computer vision for plant science by making a standard against which this and all future projects in the area can be judged - there are no other public datasets for this kind of research. 

The chosen plant (Arabidopsis Thaliana), is used by biologists as a model organism. This plant is of particular use to the current research project for two reasons: firstly it grows quickly so a full life cycle can be captured on time lapse in a matter of months; and secondly, biologists are interested in precise measurements of the way this plant grows, as its genome has been completely mapped, making it a common object of study in phenomics. Phenomics is the study of the way in which genes and environment interact to produce an organism - a phenome; this involves monitoring precisely the way an organism grows in or reacts to specific environmental situations (phenotyping). Within plant phenomics, monitoring has traditionally been through destructive measures (dissection) or hand measurement; this has clear associated costs both in terms of time and in terms of plants. The relation to phenomics, and in particular the UK's National Plant Phenomics Centre, mean that research in this project has a clear target audience (plant biologists). It is anticipated that in future, the kinds of software and algorithms devised during this project will be extended to other varieties of plants, and will become more widespread, contributing to plant monitoring systems for broader agricultural or even hobbyist gardener usage.</gtr:abstractText><gtr:potentialImpactText>The beneficiaries of this research will be, in the immediate future, academics within computer science and biology. Within computer science the research described in this proposal follows two main avenues of research: occlusion reasoning, and the modeling of growth with morphological change. This research will also provide new techniques within biology, which in turn will provide access to more detailed information about he growth of plants from a dynamic perspective. The main pathways to this academic impact come from the dataset proposed in WP1 and the workshop proposed during WP5.

Looking at the pipeline for future scientific research and researchers, this proposal also has an explicit public engagement element aimed at the next generation of scientists: building a workshop to take into schools. This workshop will involve secondary school students in practical activities that illustrate the science developed during this work, emphasising the ways in which computer science can help plant science, and in which plant science can provide interesting and challenging test cases for computer science. The workshop will be created, trialled in local schools, and then released as a &amp;quot;workshop in a box&amp;quot; enabling broader uptake across the computer vision and plant science communities.

In the medium term, the ability to model and measure plant growth in the field, using time-lapse photography, will benefit a very broad range of people. Accurate, cost-effective measurement of plant characteristics - particularly dynamic plant characteristics - will enable better plant breeding and a better understanding of the relationship between plant genetics, growing environment, and plant health. Algorithms and software such as those developed as part of this research proposal are a key step on the way to fully automated plant monitoring. This is of interest to plant breeders, the food industry, and agriculture in general. It is even of interest to (and has impact upon) hobbyist plant growers: if we can monitor plant growth for phenomics and breeding purposes, we can also monitor plant growth to determine whether the watering regime is right in someone's greenhouse.

Looking further into the future (10-50 years), food security is a key problem of national and international importance: being able to breed for dynamic plant characteristics (things like rapid establishment, growth, and drought resilience) and being able to measure these characteristics (accurately, with high-throughput methods like computer vision) is absolutely vital. This is of direct relevance to the question of where our future meals will come from - predictions of population growth suggest that globally, we need to become more efficient in food production simply to maintain our current levels of food consumption. In addition to food-related impact, there are energy-related impacts for computer vision in plant science: biofuels could solve energy generation problems, and phenomics is addressing some key questions in this domain too.</gtr:potentialImpactText><gtr:fund><gtr:end>2016-12-31</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2014-05-21</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>101088</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Image analysis schools workshop</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>2A39D893-4511-4677-AB5D-3D21BD8720D8</gtr:id><gtr:impact>Workshop for schools on image processing of timelapse photography of plants. Created in consultation with local schools, then released online as a &amp;quot;workshop in a box&amp;quot;. Engages children 14-16 with concepts of measurement, the idea of an image as a data source, the concept of a colour space. Relates to the image capture workshop here:
https://docs.google.com/document/d/1tXNXWhs49XUKWZl5s51mYF4Rpl44P00eih7Ulr8CHvw/edit#</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:url>https://docs.google.com/document/d/1cAqEZQ-llwgvifhOiNROsFp91AaMjjU0qJOn5F7wb5o/edit#</gtr:url><gtr:year>2016,2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Schools workshop: Plant imaging</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>17F0DE8B-FB87-4718-9E4A-556814967A88</gtr:id><gtr:impact>Workshop for schools on image capture and timelapse photography of plants. Created in consultation with local schools, then released online as a &amp;quot;workshop in a box&amp;quot;. Engages children 14-16 with concepts of measurement, ideas of automation and science, and creates for them a tailor made dataset to use in science measuring plant growth.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:url>https://docs.google.com/document/d/1tXNXWhs49XUKWZl5s51mYF4Rpl44P00eih7Ulr8CHvw/edit#</gtr:url><gtr:year>2016,2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>BMVA plants in computer vision workshop</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>A0FC0222-4526-4687-8401-FDF9E111431D</gtr:id><gtr:impact>With the British Machine Vision Association, we held a workshop at the British Computer Society on the topic of computer vision for plant science. 
This had over 90 attendees, and 12 talks from research groups in the UK and wider afield.

A special issue of the journal Plant Methods has been called for based upon this meeting: https://plantmethods.biomedcentral.com/plants-in-computer-vision</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>https://docs.google.com/document/d/1YB4PAU3P3aJe6TDDw6oVsc-GtJ_hQGUf3lsq446bRNw/edit?usp=sharing</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>In this grant we investigated the modelling of plant growth from time-lapse imagery using computer vision. The plant we investigated was Arabidopsis Thaliana (commonly just called arabidopsis), a &amp;quot;model organism&amp;quot;. 

As part of this process, we created a large dataset of timelapse imagery of plants as they grow. It consists of images of plants taken every 15 minutes, showing growth over an extended period of several weeks. As well as the photographs of plants there are annotations which show at a pixel-level individual leaf locations. In total, there are 56 annotated ground truth images containing 916 hand-marked up individual arabidopsis plants. This is a major resource for people developing computer vision algorithms; by releasing this publicly we are enabling other researchers to build on our work and to compare their results on an open challenge.

Within the problem of plants in computer vision one key question is to do with occlusions. When one leaf overlaps another, it can be hard to work out what is going on with the leaf underneath. Arabidopsis is a &amp;quot;rosette plant&amp;quot; which means that leaves grow out from the centre; this is a common growing pattern and what it means is that leaves which are covered up have in the past been visible. However when a leaf overlaps a leaf we end up with an edge that is green-on-green so it can be very difficult to see, and easily confused with leaf features like veins or spurious edges caused by shadows. We have developed a new method for classifying edges in plant images which makes use of convolutional neural networks. This has been presented in several meetings and workshops, and is currently being developed into a journal paper.
- How might the findings be taken forward and by whom?</gtr:description><gtr:exploitationPathways>This work can be taken forward immediately by any researchers wishing to use our public dataset of plant images with annotations. This provides the ability for robust algorithm development through shared benchmark sets, and it also provides a novel set of sub-plant labelled leaf images.</gtr:exploitationPathways><gtr:id>8D6ED73B-7C9B-480B-9965-C86B19AE9670</gtr:id><gtr:sectors><gtr:sector>Agriculture, Food and Drink,Environment</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>It is a visible light, top down, timelapse image dataset of Arabidopsis thaliana (Arabidopsis). It incorporates the original images, some with leaf-level ground truth annotations, harvested plant ground truth data and scanned images together with supporting software.

 - 4 sets of 20 Arabidopsis Thaliana plants have been grown in trays
 - Images of each tray are taken in a 15 minute timelapse sequence using a robotic greenhouse system
 - Periodically, plants from each tray are sacrificed to record destructive measurements
 - A subset of these images have been hand-annotated to provide leaf-based image ground truth.
In total, there are 56 annotated ground truth images containing 916 hand-marked up individual arabidopsis plants
We also release software to help with the analysis of these images</gtr:description><gtr:id>B99BF03B-B9C3-4C72-A839-3B0A2CF9A8F4</gtr:id><gtr:impact>This is the first leaf-level dataset with high temporal resolution, physical ground truth and hand labelled leaf identities. 
It is proposed to use these images as part of a plant-imaging challenge workshop.</gtr:impact><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>ALED: Aberystwyth Leaf Evaluation Dataset</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>https://zenodo.org/record/168158#.WL2EbB_6xZU</gtr:url><gtr:yearFirstProvided>2016</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>A new measure for the evaluation of region level segmentation of objects, as applied to evaluating the accuracy of leaf-level segmentation of plant images. The proposed approach enforces the rule that a region (e.g. a leaf) in either the image being evaluated or the ground truth image evaluated against can be mapped to no more than one region in the other image. We call this measure the subset-matched Jaccard index.</gtr:description><gtr:id>32E26438-9BF8-4A41-9475-ED5A12BBAC72</gtr:id><gtr:impact>This enables more precise evaluation of leaf-segmentations.</gtr:impact><gtr:title>The subset-matched Jaccard index for evaluation of Segmentation for Plant Images</gtr:title><gtr:type>New/Improved Technique/Technology</gtr:type><gtr:url>https://arxiv.org/pdf/1611.06880.pdf</gtr:url><gtr:yearFirstProvided>2016</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/9DE250E2-4A88-41F6-B8AA-671E5784E28D"><gtr:id>9DE250E2-4A88-41F6-B8AA-671E5784E28D</gtr:id><gtr:title>Watching plants grow - a position paper on computer vision and Arabidopsis thaliana</gtr:title><gtr:parentPublicationTitle>IET Computer Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/7f7afdd34c1ae857c662de9e5225286d"><gtr:id>7f7afdd34c1ae857c662de9e5225286d</gtr:id><gtr:otherNames>Bell J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/L017253/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>