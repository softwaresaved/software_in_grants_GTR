<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/68D0E3C9-9246-4CFC-B5E9-48584CF82993"><gtr:id>68D0E3C9-9246-4CFC-B5E9-48584CF82993</gtr:id><gtr:name>University of Manchester</gtr:name><gtr:department>Life Sciences</gtr:department><gtr:address><gtr:line1>Oxford Road</gtr:line1><gtr:city>Manchester</gtr:city><gtr:postCode>M13 9PL</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/68D0E3C9-9246-4CFC-B5E9-48584CF82993"><gtr:id>68D0E3C9-9246-4CFC-B5E9-48584CF82993</gtr:id><gtr:name>University of Manchester</gtr:name><gtr:address><gtr:line1>Oxford Road</gtr:line1><gtr:city>Manchester</gtr:city><gtr:postCode>M13 9PL</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/B9585634-D1B0-4CF9-AC66-B3D5D25531DC"><gtr:id>B9585634-D1B0-4CF9-AC66-B3D5D25531DC</gtr:id><gtr:firstName>William</gtr:firstName><gtr:otherNames>Irvin</gtr:otherNames><gtr:surname>Sellers</gtr:surname><gtr:orcidId>0000-0002-2913-5406</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=NE%2FJ012556%2F1"><gtr:id>7F83D7AC-C8BE-461D-AB19-D1B5D2A3E37C</gtr:id><gtr:title>Markerless Motion Capture for Primate Locomotion Studies</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>NE/J012556/1</gtr:grantReference><gtr:abstractText>Humans are unique in the way they move since we are the only animal that is able to walk on fully straight legs. We think that this feature occurred very soon after the human lineage split off from the chimpanzee lineage so that understanding how we came to move the way we do will help us understand how this split occurred. To understand the evolution of human walking and running we need to also know about how our nearest relatives walk and run and that has led to many researchers studying non-human primate locomotion. The commonest approach is simply to use a video camera and film what the animal is doing. However in practice there are many difficulties with this technique. To take measurements from video film either requires us to put reflective markers on the study animal which is usually simply not possible, or the individual frames need be measured individually by a skilled researcher estimating where the primate's joints are. This is not very accurate because often the joint positions are obscured by hair. Often we want to understand what is happening in 3D since primates spend a lot of time in the trees and their movements are very complex and this is particularly difficult to quantify from simple video analysis. Fortunately in the last few years computer technology has advanced to such an extent that we can reconstruct three-dimensional shape from a series of photographs as long as they overlap. This stereo reconstruction works by identifying common features in much the same way that the stereoscopic vision works in our eyes. With high definition video it is therefore possible to extract the skin outline of a subject animal in 3D. This is only half the battle since what we really want to know is how the skeleton is moving underneath the skin. Fortunately we also have accurate 3D models of the skeleton obtained from CT scans that can be fitted within the skin envelope and this should give us the information we require. The purpose of this project is to test the effectiveness of this new approach. We can compare the results we obtain using the new technique against those we obtain using a range of alternative standard techniques. By using trained monkeys in controlled conditions as our study animals we can even use the very accurate marker based systems as a 'gold-standard' reference to identify what the limitations of the new technique are, and by trying the technique on a range of different animals we can see whether features of the fur such as hair-length or colour cause any problems. The ultimate goal is to produce a much better technique for studying primate locomotion that will greatly reduce the effort required whilst at the same time producing better results. This improved data is necessary to allow us to understand the full complexity of the evolution of the way modern humans move and how we differ from our nearest relatives among the primates.</gtr:abstractText><gtr:potentialImpactText>The main value of research into human evolution is cultural. There is intense interest in our evolutionary history and research of this nature will be widely reported in the traditional media as well as online, and through more educational outlets such as museums. This provides economic benefits through the various media industries although the monetary value is unlikely to be large. Of more concrete value is the technique itself since motion capture is now widely used in the television, film and computer game industries. Whilst marker-based human motion capture is the commonest technique there are plenty of occasions where non-marker or non-human motion capture is required and the approached developed by this project will be useful in these cases.</gtr:potentialImpactText><gtr:fund><gtr:end>2013-09-02</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/8A03ED41-E67D-4F4A-B5DD-AAFB272B6471"><gtr:id>8A03ED41-E67D-4F4A-B5DD-AAFB272B6471</gtr:id><gtr:name>NERC</gtr:name></gtr:funder><gtr:start>2012-09-03</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>36354</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>We have developed a technique for producing 3D motion capture data from uncalibrated, synchronised cameras. This technique is the first time that accurate 3D data can be obtained from unmarked animals under semi free-ranging conditions.</gtr:description><gtr:firstYearOfImpact>2014</gtr:firstYearOfImpact><gtr:id>AD9337CF-EF06-4F47-9CC1-26AB6108EEE1</gtr:id><gtr:impactTypes><gtr:impactType>Cultural</gtr:impactType></gtr:impactTypes><gtr:sector>Digital/Communication/Information Technologies (including Software),Culture, Heritage, Museums and Collections</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>Animals move in amazing ways and understanding how they manage this may let us build robotic devices that can move in similar fashions. However it is very difficult to measure these movements accurately with animals that are not in the laboratory. We have come up with a video based technique that lets us measure movements in animals in free ranging conditions such as a zoos and wildlife parks and this lets us take the precise measurements that we need.</gtr:description><gtr:exploitationPathways>This technique is widely applicable for motion capture when markers cannot be put on the subject. We are using it for animal work but there are plenty of situations where it would be appropriate for humans too. Motion capture is widely used in humans diagnostically and also for computer games and movie special effects.</gtr:exploitationPathways><gtr:id>210E7EA4-7265-4F18-A1C4-015E711E9E38</gtr:id><gtr:sectors><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software),Healthcare,Culture, Heritage, Museums and Collections</gtr:sector></gtr:sectors><gtr:url>http://www.animalsimulation.org</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>This is an application that allows the user to manually digitise regions on the point clouds obtained through video photogrammetry.</gtr:description><gtr:id>444A52BC-5906-4567-BFAC-B54BE7FD5FF9</gtr:id><gtr:impact>None yet.</gtr:impact><gtr:openSourceLicense>true</gtr:openSourceLicense><gtr:title>CloudDigitiser</gtr:title><gtr:type>Software</gtr:type><gtr:url>http://www.animalsimulation.org</gtr:url><gtr:yearFirstProvided>2014</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/EEEE8129-C720-4019-B47E-E325E1E1FDCF"><gtr:id>EEEE8129-C720-4019-B47E-E325E1E1FDCF</gtr:id><gtr:title>Markerless 3D motion capture for animal locomotion studies.</gtr:title><gtr:parentPublicationTitle>Biology open</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/9f45a7743d08dd09b61af670ee3819b9"><gtr:id>9f45a7743d08dd09b61af670ee3819b9</gtr:id><gtr:otherNames>Sellers WI</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>2046-6390</gtr:issn></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">NE/J012556/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>33</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>6AECCE8F-D1A3-43C8-B6DC-7B2289BE3CBF</gtr:id><gtr:percentage>34</gtr:percentage><gtr:text>Archaeology</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>FB535BD0-E265-4C0A-8532-32DCB83A3951</gtr:id><gtr:percentage>33</gtr:percentage><gtr:text>Tools, technologies &amp; methods</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>CF888A60-6892-4111-A23F-E8A95D103915</gtr:id><gtr:percentage>33</gtr:percentage><gtr:text>Musculoskeletal system</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>59A2A0A2-345A-4E14-85F6-936CA1B268C4</gtr:id><gtr:percentage>34</gtr:percentage><gtr:text>Science-Based Archaeology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>4A6E5CEB-ACA3-4301-98AD-C7EC310948FD</gtr:id><gtr:percentage>33</gtr:percentage><gtr:text>Theoretical biology</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>