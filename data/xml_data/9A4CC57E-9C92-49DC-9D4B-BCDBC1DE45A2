<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/D1774113-D5D2-4B7C-A412-66A90FE4B96F"><gtr:id>D1774113-D5D2-4B7C-A412-66A90FE4B96F</gtr:id><gtr:name>University of Cambridge</gtr:name><gtr:department>Engineering</gtr:department><gtr:address><gtr:line1>Lensfield Road</gtr:line1><gtr:line4>Cambridge</gtr:line4><gtr:postCode>CB2 1EW</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/D1774113-D5D2-4B7C-A412-66A90FE4B96F"><gtr:id>D1774113-D5D2-4B7C-A412-66A90FE4B96F</gtr:id><gtr:name>University of Cambridge</gtr:name><gtr:address><gtr:line1>Lensfield Road</gtr:line1><gtr:line4>Cambridge</gtr:line4><gtr:postCode>CB2 1EW</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/AFE5C6FD-3500-44F6-B100-184B5F2FD0D7"><gtr:id>AFE5C6FD-3500-44F6-B100-184B5F2FD0D7</gtr:id><gtr:name>Microsoft Research</gtr:name><gtr:address><gtr:line1>One Microsoft Way</gtr:line1><gtr:line4>Redmond</gtr:line4><gtr:line5>Washington 98052</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/7D1FF4C7-DD25-4073-920E-B040B150B711"><gtr:id>7D1FF4C7-DD25-4073-920E-B040B150B711</gtr:id><gtr:name>Google Inc</gtr:name><gtr:address><gtr:line1>1600 Amphitheatre Parkway</gtr:line1><gtr:line2>Building 42</gtr:line2><gtr:postCode>94043</gtr:postCode><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/19644475-193C-4F3D-AA01-D874F368FB31"><gtr:id>19644475-193C-4F3D-AA01-D874F368FB31</gtr:id><gtr:name>Honeywell UK</gtr:name><gtr:address><gtr:line1>Newhouse</gtr:line1><gtr:postCode>ML1 5SB</gtr:postCode><gtr:region>Unknown</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/60484E4D-D8C2-4A23-94F6-1816F74E5DE2"><gtr:id>60484E4D-D8C2-4A23-94F6-1816F74E5DE2</gtr:id><gtr:name>Dexta Robotics</gtr:name><gtr:address><gtr:line1>Building A1613</gtr:line1><gtr:line2>Huanan Town</gtr:line2><gtr:line3>Longgang</gtr:line3><gtr:region>Unknown</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/B3980ADD-58CF-4A26-B922-E005960588A6"><gtr:id>B3980ADD-58CF-4A26-B922-E005960588A6</gtr:id><gtr:firstName>Per Ola</gtr:firstName><gtr:surname>Kristensson</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FR004471%2F1"><gtr:id>9A4CC57E-9C92-49DC-9D4B-BCDBC1DE45A2</gtr:id><gtr:title>Design the Future 2: CrowdDesignVR</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/R004471/1</gtr:grantReference><gtr:abstractText>Our initial proposal CrowdDesign set out to explore how we can aid rapid prototyping of mobile sensor-based user interfaces by exploiting the versatile sensor capabilities of mobile phones. The primary objective was to investigate if we can crowdsource such sensor-dependent tasks to mobile devices in order to assist designers in rapidly evaluating new interaction techniques in situ. We have identified a very strong research trajectory that motivates continuing the CrowdDesign project beyond this year: CrowdDesignVR. In this follow-up project we propose to substantially extend the scope of the CrowdDesign project and elevate it from the smartphone platform and into a virtual reality platform. To enable the exploration of a very promising research trajectory for crowdsourced human-computer interaction, we need to invest time and effort into realising a high-quality crowdsourcing platform for VR.

CrowdDesignVR will be the first crowdsourcing system for virtual reality. It will distribute tasks across the Steam VR distribution network, which allows it to reach a large sample of VR users. Prior research cannot reach this scale, as research has been limited to opportunity-sampling local participants and then train them to use a specific VR system. In contrast, by enabling access to thousands or even tens of thousands of Steam users, CrownDesignVR facilitates user interaction data collection at a scale that is several orders of magnitudes larger. This provides a number of wider benefits: 1) we can during the course of the project create more accurate models of human actions; 2) we can collect sufficient training data to train machine learning models, such as deep neural network models to accurately decode common user interface interaction patterns, such as typing, gesturing and determining whether an action was intended or not by the user.

Since crowdsourcing tasks in a high-fidelity VR environment is a new avenue of research, there are many fundamental questions that need to be answered. We believe this project could result in potential seminal work on the understanding of the design space for crowdsourcing in VR.

Another potential impact is the data itself. Our internal work on building deep neural networks for decoding typing tasks on touchscreen and physical keyboards has revealed that deep neural networks (specifically, recurrent neural networks) output traditional hidden Markov model decoding. However, we have also found that the amount of data that needs to be collected is very large, in fact, we use our CrowdDesign task architecture as mentioned previously in our report to collect touchscreen data from hundreds of users. CrowdDesignVR can substantially widen the scope and let us tackle some of deep previously unsolved questions in user interface design, such as how we can build a gesture recogniser that is capable of learning to recognise both open-loop (direct recall from motor memory) and closed-loop (visually-guided motion) gestures on both the 2D plane and in 3D space. A large amount of data would allow us to train a recurrent neural network to learn this separation. The potential is large as users are always in a continuum between open-loop and closed-loop interaction. However, due to the fundamental differences in the underlying generative models that result in the observed behaviour, it is very difficult to collect sufficient training data in lab.</gtr:abstractText><gtr:potentialImpactText>Academic Dissemination
We will strive to publish in the top venues in our discipline, the CHI conference and ACM Transactions on Computer-Human Interaction (TOCHI) primarily. Other venues we will consider are the Ubicomp, UIST and ISMAR conferences and IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI). We will also propose a workshop or tutorial at CHI to invite other researchers to explore this research area.

Ensuring Lasting Impact of the Project
At month 30 we will assess the success of the platform with the assistance of our industry partners. If the platform has a substantial uptake we will investigate commercial or non-profit avenues for enabling the platform to stay open. Our experience is that it is very difficult to maintain a platform without recurring income funding it. Therefore, if the platform is to last we are going to develop a business model for sustaining it in consultation with Cambridge Enterprise, who has advised on similar models before, such as Granta Design. We may also choose to explore a partnership with our industry partners.

We also believe there is a potential to excite, entice and engage the players on the platform themselves who are using the platform. We are all affected by user interface issues and many users are interested in the mechanisms behind them. Therefore, in line with the ethos of the CrowdDesign project, we will attempt to treat users on the platform as first-class citizens when it is opened up so that they themselves can explore user interface tasks on the platform they are using.

Finally, we will strive to release data openly using the Cambridge open data repository.

University and Departmental Support
The University of Cambridge and the Department of Engineering has experience in supporting technology start-ups and other translational activities. We will consult with Cambridge Enterprise to explore avenues for potential commercial or non-profit exploitation of the data, models, algorithms and platform.</gtr:potentialImpactText><gtr:fund><gtr:end>2020-12-31</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2018-01-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>560504</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">EP/R004471/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>0AD041FC-DCB2-46BB-B9CC-ADDFF2FA5E17</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Human-Computer Interactions</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>