<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/4A348A76-B2D0-4DDD-804A-CE735A6D3798"><gtr:id>4A348A76-B2D0-4DDD-804A-CE735A6D3798</gtr:id><gtr:name>University of Bristol</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Senate House</gtr:line1><gtr:line4>Bristol</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BS8 1TH</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/4A348A76-B2D0-4DDD-804A-CE735A6D3798"><gtr:id>4A348A76-B2D0-4DDD-804A-CE735A6D3798</gtr:id><gtr:name>University of Bristol</gtr:name><gtr:address><gtr:line1>Senate House</gtr:line1><gtr:line4>Bristol</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BS8 1TH</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/AC63D12E-73C5-4845-8515-65B6864C0FDE"><gtr:id>AC63D12E-73C5-4845-8515-65B6864C0FDE</gtr:id><gtr:name>XMOS Ltd</gtr:name><gtr:address><gtr:line1>Venturers House</gtr:line1><gtr:line2>King Street</gtr:line2><gtr:line4>Bristol</gtr:line4><gtr:postCode>BS1 4PB</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/F262B9E0-E9D1-4BFF-B9BF-B4C81D12D8B9"><gtr:id>F262B9E0-E9D1-4BFF-B9BF-B4C81D12D8B9</gtr:id><gtr:name>Microsoft Research Ltd</gtr:name><gtr:address><gtr:line1>21 Station Road</gtr:line1><gtr:postCode>CB1 2FB</gtr:postCode><gtr:region>Unknown</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/DAEF99A9-72B9-4731-A043-5992F34C2E7A"><gtr:id>DAEF99A9-72B9-4731-A043-5992F34C2E7A</gtr:id><gtr:firstName>Sriram</gtr:firstName><gtr:surname>Subramanian</gtr:surname><gtr:orcidId>0000-0002-5266-8366</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/3A6EFFA7-3655-407C-9FDF-F703DE9B65F8"><gtr:id>3A6EFFA7-3655-407C-9FDF-F703DE9B65F8</gtr:id><gtr:firstName>Bruce</gtr:firstName><gtr:surname>Drinkwater</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FJ004448%2F1"><gtr:id>FF35DDD5-CBBC-463D-8080-F10B47E4D943</gtr:id><gtr:title>Exploration of Ultrasound based haptic interaction on a multi-touch surface</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/J004448/1</gtr:grantReference><gtr:abstractText>Multi-touch tables, such as Microsoft Surface, are now widely available. Users can walk-up and use these systems in hotel lobbies and other public settings with very little instruction and with no need to wear or hold intrusive sensors with their hands or body. The ability to 'walk-up and use' with unadorned hands and fingers removes the barrier between human and technology, encouraging spontaneous use. 

One of the primary disadvantages of current interactive surfaces is that users can touch objects, but they are unable to feel them. There are a plethora of applications where it is beneficial for the user to have their touches augmented with 'feel-based' haptic feedback. For example, medical applications, virtual training, and modelling applications require precise control from the user-haptic feedback can aid the user in effectively performing these tasks. These applications demonstrate the benefit of augmenting haptic feedback with visual feedback in an interactive application. Often, the visual space has been disconnected from the force-feedback, requiring a prolonged training period for the user to become accustomed to moving a digital object and watching the interactions a small distance away on a monitor. 

In this proposal we will investigate the use of ultrasound transducers to provide 'feelable' feedback through air. The skin on a human hand can feel the ultrasonic pressure wave produced by a carefully calibrated series of transducers, in much the same manner that is apparent from loud sub-woofers on a stereo system. Ultrasound waves are outside the human's range of hearing and so provide silent, through-air haptic feedback. We will use this technology to provide multi-point haptic feedback on the surface of a multi-touch horizontal surface.

The team consists of Dr. Sriram Subramanian, Dr. Mark Marshall and Dr. Jason Alexander from the computer science departments and Prof. Bruce Drinkwater from the Mechanical Engineering department of the University of Bristol and Prof. Stephen Brewster from the Computer Science department of the University of Glasgow. The team is internationally recognised for its research in Human-Computer Interaction (HCI), novel integration of hardware for HCI, and Ultrasonic sensors. Microsoft research (Cambridge) and XMOS will serve as project partners and offer valuable resources and support for the project.</gtr:abstractText><gtr:potentialImpactText>Development of ultrasonic haptic feedback has the potential to not only revolutionise several current areas of research, but to also create opportunities for immersive new experiences with large commercial value. Haptics is currently a hot topic in industry (Next Generation Haptics: Market Analysis and Forecasts. ARC Chart. Feb 2011.www.arcchart.com) and our work will develop a new form of haptic technology and demonstrate its usefulness in a new range of areas. This will increase the potential opportunities for haptics beyond what is available now. 

Our demonstrator systems (as listed in WP5) will allow Dynamic Holographic Assembler (DHA) operators to feel the forces required to move molecules on their multi-touch interfaces to these systems (currently force data cannot be used in any way as it is difficult to let users feel forces at multiple locations simultaneously). This will provide added value to current research in this area funded through EPSRC (EP/G037310/1 and EP/G012067/1). In turn, this will allow non-specialist researchers to also use a DHA with minimal training.

Once we have developed the technology and interaction techniques that support multi-point haptic feedback, there is a large number of potential domains for applying these techniques. Examples of these applications include mobile TV broadcasting and medical applications. Mobile TV broadcasts could be augmented with a haptic feedback channel to let users 'feel' the action. For example, multi-point ultrasonic haptic feedback could be applied to the back of the mobile device, with the user's hand sensing the forces exerted by the athletes. The gloves of amateur boxers already include sensors for registering the force of their punches-this data could be transmitted with the video stream to provide a more immersive user experience. A demonstrator for this application will be developed by a project technician to showcase this idea. 
There are also several medical applications for this technology. Stem-cell researchers can also use multi-point haptic feedback as a method for interpreting, through mechanical property changes, structural changes in the cell even before chemical or other visible identification is possible.</gtr:potentialImpactText><gtr:fund><gtr:end>2015-01-31</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2012-02-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>335832</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs><gtr:artisticAndCreativeProductOutput><gtr:description>The output of the project was part of the BBC Christmas lectures from 2014. This was presented by Dr. Daniella George</gtr:description><gtr:id>44580818-8560-42A0-8E6C-5AB184A6DEB9</gtr:id><gtr:impact>Publicity and enhanced awareness of our system and research.</gtr:impact><gtr:title>BBC Christmas Lecture</gtr:title><gtr:type>Film/Video/Animation</gtr:type><gtr:url>http://www.bbc.co.uk/programmes/b04wgf6g</gtr:url><gtr:yearFirstProvided>2014</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>Ultrahaptics was featured in the artworks created by Flying Objects in 2015 as part of their winning entry to the Tate Moderns IK prize 2015. 
This was an installation of sensory stimulants which will allow users to smell, touch, taste and hear works of art. Ultrahaptics technology was used to create teh &amp;quot;touch&amp;quot; art work.</gtr:description><gtr:id>AA653A62-7ECE-4E23-81ED-E989DA0DA3A6</gtr:id><gtr:impact>The involvement of Ultrahaptics was through the University of Sussex (Dr. Marianna Obrist). 
The art piece was a huge success both within UK and beyond. It helped establish Ultrahaptics as a technology company that works with the creative industry. We got a lot of press coverage for this. 

Wall Street Journal - https://www.wsj.com/articles/please-touch-the-art-work-new-tate-exhibit-will-stimulate-all-five-senses-1439495457

The Independent - http://www.independent.co.uk/arts-entertainment/art/news/tate-sensorium-new-exhibition-at-tate-britain-invites-art-lovers-to-taste-smell-and-hear-art-10438783.html</gtr:impact><gtr:title>Part of Tate Modern IK prize 2015</gtr:title><gtr:type>Artistic/Creative Exhibition</gtr:type><gtr:url>http://www.tate.org.uk/about/projects/ik-prize/ik-prize-2015</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput></gtr:artisticAndCreativeProductOutputs><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>We are talking to many potential end-users ranging from automotive to consumer electronics and home appliances. 
All these avenues for further commercial exploitation is being explored through our startup Ultrahaptics. 

This project has also spawned further research interest in techniques for acoustic levitation. 

Acoustic Levitation has resulted in a new EPSRC proposal EP/N014197/1

Ultrahaptics is a Bristol based company that currently employs 25 people. More information can be found at www.ultrahaptics.com

Updated on Feb 3 2017
Today Ultrahaptics is an international company with 50 employees in the UK and a second office in California. We have several positions that still need to be filled (we will grow to 100 employees in UK by the end of the year and we will be hiring additional employees in the US). We have several customers and a steady revenue. The company is always on the media spot-light. In January 2017, Bosch unveiled their car dashboard (@CES 2017) which included the Ultrahaptics prototype (https://techcrunch.com/2017/01/03/ultrahaptics-launching/).

 Similarly, many other companies have made public press releases that confirm our involvement with them. We expect multiple consumer facing products to be launched in the coming months.</gtr:description><gtr:firstYearOfImpact>2013</gtr:firstYearOfImpact><gtr:id>36DB08F0-3A12-46BE-9269-2F22B307FDCB</gtr:id><gtr:impactTypes><gtr:impactType>Economic</gtr:impactType></gtr:impactTypes><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software),Electronics,Transport</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The project examined ways of creating tactile feedback on different interactive surfaces (like tablets). We examined the use of ultrasound transducers to create such tactile sensations and how this could be applied within the context of human-computer interaction.</gtr:description><gtr:exploitationPathways>A spin-off company called ultrahaptics has been setup to commercialise the findings of this project.</gtr:exploitationPathways><gtr:id>71365EA3-7803-45D3-9F0E-E848018E86E4</gtr:id><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Electronics,Transport</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs><gtr:spinOutOutput><gtr:companyName>Ultrahaptics</gtr:companyName><gtr:description>Ultrahaptics creates tactile sensations in mid-air. No gloves or attachments, the feeling is projected onto your bare hands.</gtr:description><gtr:id>F76D953A-B7FC-431A-BA08-D5D95008A066</gtr:id><gtr:impact>none yet.</gtr:impact><gtr:url>http://www.ultrahaptics.com</gtr:url><gtr:yearCompanyFormed>2013</gtr:yearCompanyFormed></gtr:spinOutOutput></gtr:spinOutOutputs></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/2B2DC644-33D7-494D-8CDC-3732DF8EDD9C"><gtr:id>2B2DC644-33D7-494D-8CDC-3732DF8EDD9C</gtr:id><gtr:title>Ultrasonic Haptic Feedback for Gestural Interfaces using a Moveable Hand-Mounted Array</gtr:title><gtr:parentPublicationTitle> -</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/0807d7227dd5eebad39a83939c374db5"><gtr:id>0807d7227dd5eebad39a83939c374db5</gtr:id><gtr:otherNames>Wilson, Graham</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/59AEDB59-5242-469F-854C-60F96B935943"><gtr:id>59AEDB59-5242-469F-854C-60F96B935943</gtr:id><gtr:title>Talking about tactile experiences</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/235d656de2bb030d18dedebe8d8ef672"><gtr:id>235d656de2bb030d18dedebe8d8ef672</gtr:id><gtr:otherNames>Obrist M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:isbn>9781450318990</gtr:isbn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/D9491788-585F-4182-8E42-0694634A4134"><gtr:id>D9491788-585F-4182-8E42-0694634A4134</gtr:id><gtr:title>Dexterous ultrasonic levitation of millimeter-sized objects in air.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on ultrasonics, ferroelectrics, and frequency control</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/b84f70cbd0def70d0ab927629cf93e91"><gtr:id>b84f70cbd0def70d0ab927629cf93e91</gtr:id><gtr:otherNames>Seah SA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0885-3010</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/8BC27EBE-64A8-4A2D-A68F-CE949FDF2644"><gtr:id>8BC27EBE-64A8-4A2D-A68F-CE949FDF2644</gtr:id><gtr:title>Perception of ultrasonic haptic feedback on the hand</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/deb5f0f607f9a5b24127fdedd8ca5fb7"><gtr:id>deb5f0f607f9a5b24127fdedd8ca5fb7</gtr:id><gtr:otherNames>Wilson G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:isbn>9781450324731</gtr:isbn></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/J004448/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>0AD041FC-DCB2-46BB-B9CC-ADDFF2FA5E17</gtr:id><gtr:percentage>40</gtr:percentage><gtr:text>Human-Computer Interactions</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>60</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>