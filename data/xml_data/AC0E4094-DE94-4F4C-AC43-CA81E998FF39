<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/936D002F-A8D1-4A93-AE5D-825ED0903D8D"><gtr:id>936D002F-A8D1-4A93-AE5D-825ED0903D8D</gtr:id><gtr:name>University of Nottingham</gtr:name><gtr:department>Sch of Psychology</gtr:department><gtr:address><gtr:line1>University Park</gtr:line1><gtr:line4>Nottingham</gtr:line4><gtr:line5>Nottinghamshire</gtr:line5><gtr:postCode>NG7 2RD</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/936D002F-A8D1-4A93-AE5D-825ED0903D8D"><gtr:id>936D002F-A8D1-4A93-AE5D-825ED0903D8D</gtr:id><gtr:name>University of Nottingham</gtr:name><gtr:address><gtr:line1>University Park</gtr:line1><gtr:line4>Nottingham</gtr:line4><gtr:line5>Nottinghamshire</gtr:line5><gtr:postCode>NG7 2RD</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/A860D076-ED7B-439C-AB71-04DD7C2A9D3E"><gtr:id>A860D076-ED7B-439C-AB71-04DD7C2A9D3E</gtr:id><gtr:firstName>Geoffrey</gtr:firstName><gtr:surname>Underwood</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FE006329%2F1"><gtr:id>AC0E4094-DE94-4F4C-AC43-CA81E998FF39</gtr:id><gtr:title>Exploiting spatial cognition in picture database design</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/E006329/1</gtr:grantReference><gtr:abstractText>The commercial and functional potential of picture databases is very great for a range of applications from medicine to medieval history. However, this potential is proving difficult to deliver and research activity in this area is intense. There are two principal approaches: i) extending existing methods to encode pictures by description and keywords; and ii) computational analysis of images to capture superficial aspects such as colour and texture; aiming to remove the effort of entering pictures into a database and to allow user's crude depictions to access subsets of pictures to be searched for recognition. However, current opinion suggests neither approach is likely in the medium term to deliver cost-effective solutions to the problem except in highly specialised areas.Our research proposes to innovate by considering the problem from a third, psychological, perspective: human spatial cognition is robust, and we are generally good at inspecting pictures and recalling their spatial layout later. Furthermore, the layout of most images can be described in ways that preserve elements of meaning and visual distinctiveness. Ideally therefore, databases that encode location information in pictures, and allow users to use that information in retrieval, represent a match of human skills with a method generally applicable to most task domains. To this end, this proposal links two lines of psychological research. First, we are interested in visual attention: how do people look at pictures? For the purposes of database design, we are interested in the relationship between picture content and attention; as expressed in eye movements. Although eye movements are variable, they do show elements of consistency. We will be concerned with how best to represent and evaluate this consistency as a function of factors such as: the picture content; different observers; task domain; and delay between storage and retrieval.Second, we aim to study how the spatial layout of images is remembered as a consequence of attention. Can we use our understanding of visual attention processes (and eye movements in particular) to predict spatial recall? How precise is this spatial knowledge, how could it be used, and how discriminating is it in the retrieval of images from a database? There are two issues here: (i) We know that some location knowledge is acquired very quickly in the inspection processes. This is also the stage when the viewer's eye movements are more predictable by computer because they are driven by visual analysis of the image and less upon its meaning. It follows that if we can model the relationship between early eye movements and location memory, and if that memory is useful in retrieval, then some indexing of pictures into databases can be automated. This research aims to evaluate this potential; (ii), As inspection continues, eye movements become harder to predict as the viewer's understanding of the content of the image develops. We aim to show how this meaning influences eye movements and the impact of this upon location memory beyond that gained in the early stages of viewing. Overall, these two complementary questions will tell us how much picture coding can be automated and how task- and user- specific factors will influence design.As a study of the feasibility of this innovation to the design of picture databases, this proposal also considers the adaptability and efficiency of the approach in different circumstances. Accordingly, in evaluating the cost benefits to picture databases, the project will seek to measure the contribution of: domain expertise, training, and some interface design issues. This will indicate whether the approach has general applicability in picture databases or whether it is best applied to bespoke, specialist, systems where training and expertise is required.</gtr:abstractText><gtr:fund><gtr:end>2009-09-30</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2006-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>271757</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/E377B9CD-77D2-4DA3-9D89-DE417D21AD26"><gtr:id>E377B9CD-77D2-4DA3-9D89-DE417D21AD26</gtr:id><gtr:title>Domain knowledge moderates the influence of visual saliency in scene recognition.</gtr:title><gtr:parentPublicationTitle>British journal of psychology (London, England : 1953)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/b1ba08681195dbad60004d4e8c473955"><gtr:id>b1ba08681195dbad60004d4e8c473955</gtr:id><gtr:otherNames>Humphrey K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0007-1269</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/EEC07E8A-00AF-4DC2-BB76-ED9CFC923EB0"><gtr:id>EEC07E8A-00AF-4DC2-BB76-ED9CFC923EB0</gtr:id><gtr:title>Turning the world around: patterns in saccade direction vary with picture orientation.</gtr:title><gtr:parentPublicationTitle>Vision research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/62949799587c7c50f3641536abd38b5c"><gtr:id>62949799587c7c50f3641536abd38b5c</gtr:id><gtr:otherNames>Foulsham T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:issn>0042-6989</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/0703C638-F155-4CC9-9A42-D8F425908C71"><gtr:id>0703C638-F155-4CC9-9A42-D8F425908C71</gtr:id><gtr:title>Cognitive Processes in Eye Guidance: Algorithms for Attention in Image Processing</gtr:title><gtr:parentPublicationTitle>Cognitive Computation</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/ec33cb31ef3b46100cbab5b0b62dd89e"><gtr:id>ec33cb31ef3b46100cbab5b0b62dd89e</gtr:id><gtr:otherNames>Underwood G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/1261CBA5-6D8C-44BE-B39B-E0C9D2EFC557"><gtr:id>1261CBA5-6D8C-44BE-B39B-E0C9D2EFC557</gtr:id><gtr:title>Is attention necessary for object identification? Evidence from eye movements during the inspection of real-world scenes.</gtr:title><gtr:parentPublicationTitle>Consciousness and cognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/ec33cb31ef3b46100cbab5b0b62dd89e"><gtr:id>ec33cb31ef3b46100cbab5b0b62dd89e</gtr:id><gtr:otherNames>Underwood G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:issn>1053-8100</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/54C7ED78-ADBF-42A0-9139-9F570D5EE232"><gtr:id>54C7ED78-ADBF-42A0-9139-9F570D5EE232</gtr:id><gtr:title>Does conspicuity enhance distraction? Saliency and eye landing position when searching for objects.</gtr:title><gtr:parentPublicationTitle>Quarterly journal of experimental psychology (2006)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/62949799587c7c50f3641536abd38b5c"><gtr:id>62949799587c7c50f3641536abd38b5c</gtr:id><gtr:otherNames>Foulsham T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>1747-0218</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/CE23C68C-5530-4CE2-BD7A-86377F0D70A8"><gtr:id>CE23C68C-5530-4CE2-BD7A-86377F0D70A8</gtr:id><gtr:title>If Visual Saliency Predicts Search, Then Why? Evidence from Normal and Gaze-Contingent Search Tasks in Natural Scenes</gtr:title><gtr:parentPublicationTitle>Cognitive Computation</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/62949799587c7c50f3641536abd38b5c"><gtr:id>62949799587c7c50f3641536abd38b5c</gtr:id><gtr:otherNames>Foulsham T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/5851A89B-C77C-4233-91BA-13681BD6EC97"><gtr:id>5851A89B-C77C-4233-91BA-13681BD6EC97</gtr:id><gtr:title>See What I'm Saying? Expertise and Verbalisation in Perception and Imagery of Complex Scenes</gtr:title><gtr:parentPublicationTitle>Cognitive Computation</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/b1ba08681195dbad60004d4e8c473955"><gtr:id>b1ba08681195dbad60004d4e8c473955</gtr:id><gtr:otherNames>Humphrey K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/99C87E28-809B-49FD-A9AE-EB536E064D6C"><gtr:id>99C87E28-809B-49FD-A9AE-EB536E064D6C</gtr:id><gtr:title>Salience of the lambs: a test of the saliency map hypothesis with pictures of emotive objects.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/b1ba08681195dbad60004d4e8c473955"><gtr:id>b1ba08681195dbad60004d4e8c473955</gtr:id><gtr:otherNames>Humphrey K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/68B41E78-4DE2-4E3D-9C39-320B19B3515D"><gtr:id>68B41E78-4DE2-4E3D-9C39-320B19B3515D</gtr:id><gtr:title>Saliency and scan patterns in the inspection of real-world scenes: Eye movements during encoding and recognition</gtr:title><gtr:parentPublicationTitle>Visual Cognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/ec33cb31ef3b46100cbab5b0b62dd89e"><gtr:id>ec33cb31ef3b46100cbab5b0b62dd89e</gtr:id><gtr:otherNames>Underwood G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/14F2ADCB-3692-49A2-AC00-84AA5927E4BB"><gtr:id>14F2ADCB-3692-49A2-AC00-84AA5927E4BB</gtr:id><gtr:title>Cognitive Vision</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/ec33cb31ef3b46100cbab5b0b62dd89e"><gtr:id>ec33cb31ef3b46100cbab5b0b62dd89e</gtr:id><gtr:otherNames>Underwood G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:isbn>978-3-540-92780-8</gtr:isbn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/84133D0F-7DE6-4169-B395-EF61273CDE5E"><gtr:id>84133D0F-7DE6-4169-B395-EF61273CDE5E</gtr:id><gtr:title>The potency of people in pictures: evidence from sequences of eye fixations.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/b1ba08681195dbad60004d4e8c473955"><gtr:id>b1ba08681195dbad60004d4e8c473955</gtr:id><gtr:otherNames>Humphrey K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/E006329/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>CC2B62EB-22CD-45F9-A6D2-0CE29B6D90FD</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Cognitive Science Appl. in ICT</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>