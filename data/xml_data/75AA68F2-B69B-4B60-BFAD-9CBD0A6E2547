<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/67B34D05-3A52-4A09-8FF9-F2398D60E246"><gtr:id>67B34D05-3A52-4A09-8FF9-F2398D60E246</gtr:id><gtr:name>University of Surrey</gtr:name><gtr:department>Vision Speech and Signal Proc CVSSP</gtr:department><gtr:address><gtr:line1>Registry</gtr:line1><gtr:line2>Stag Hill</gtr:line2><gtr:line4>Guildford</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>GU2 7XH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/67B34D05-3A52-4A09-8FF9-F2398D60E246"><gtr:id>67B34D05-3A52-4A09-8FF9-F2398D60E246</gtr:id><gtr:name>University of Surrey</gtr:name><gtr:address><gtr:line1>Registry</gtr:line1><gtr:line2>Stag Hill</gtr:line2><gtr:line4>Guildford</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>GU2 7XH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/27C357A1-B445-4C32-9646-CBD095FFA36C"><gtr:id>27C357A1-B445-4C32-9646-CBD095FFA36C</gtr:id><gtr:firstName>John</gtr:firstName><gtr:otherNames>Philip</gtr:otherNames><gtr:surname>Collomosse</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FD055032%2F2"><gtr:id>75AA68F2-B69B-4B60-BFAD-9CBD0A6E2547</gtr:id><gtr:title>Reverse Storyboarding for Video Content Based Retrieval</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/D055032/2</gtr:grantReference><gtr:abstractText>This proposal will explore the use of storyboard sketches as a means of automatically indexing and interactively querying large video databases. In doing so we address the Computer Vision problem of video Content Based Image Retrieval (CBIR) using techniques borrowed from animation and Computer Graphics.Storyboards are a powerful visual scripting technique commonly used by animators to plan and communicate the content of their productions. In simple terms, a storyboard is a series of visual images that illustrate a film's key scenes and events. However storyboards are more than static sketches --- they also depict dynamics using a variety of motion cues borrowed from contemporary animation; streak and ghosting lines, object deformations as well as more conventional indicators such as arrow-heads. Much as an artist's sketch is spatial abstraction of a static scene, so a storyboard may be considered a spatio-temporal abstraction depicting salient instants within a image sequence (video).We argue that storyboards have a number of unique properties that can be brought to bear on video CBIR. Storyboards confer a rich vocabulary with which to concisely pose search queries. They can represent a range of dynamics such as oscillation, translation, rotation, collision and occlusion. Previous use of temporal constraints in CBIR has been limited mainly to object trajectories and scene transitions, and we believe that the ability to specify additional dynamic constraints will help to improve search accuracy and performance. Storyboards are also a highly conventional and comprehensible narrative form --- comic books, for example, are used to convey stories to non-technical audiences of all ages. Thus we believe that storyboards will also provide a natural and usable interface for video CBIR.The proposed research will build upon the PI's recent work on video stylisation; specifically on rendering video into cartoons. We will build upon our Video Paintbox software to diversify the gamut of motion cues we are able to infer from real video footage. These techniques will be harnessed to parse dynamic cues from clips stored in video databases. We will develop an ontology for the representation of dynamic cues in video, and develop novel algorithms for matching search queries to the database based on spatial and dynamic content. This work will be integrated to produce a demonstrable storyboard driven CBIR system. This system will enable us test our hypothesis that the intuitively comprehensible nature of storyboard sketches, combined with their compact representation and rich vocabulary of dynamics, may be leveraged to enhance usability, accuracy and performance of video CBIR.</gtr:abstractText><gtr:fund><gtr:end>2009-10-31</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2009-06-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>22450</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/5E4A6E47-3718-46EC-B014-CBD397780410"><gtr:id>5E4A6E47-3718-46EC-B014-CBD397780410</gtr:id><gtr:title>Gradient field descriptor for sketch based retrieval and localization</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/9fd17f711ed8bbbec34eec94ef318ae6"><gtr:id>9fd17f711ed8bbbec34eec94ef318ae6</gtr:id><gtr:otherNames>Hu R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:isbn>978-1-4244-7992-4</gtr:isbn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/B253FB04-1574-4790-8814-F699B3498BE6"><gtr:id>B253FB04-1574-4790-8814-F699B3498BE6</gtr:id><gtr:title>Motion-sketch Based Video Retrieval Using a Trellis Levenshtein Distance</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/9fd17f711ed8bbbec34eec94ef318ae6"><gtr:id>9fd17f711ed8bbbec34eec94ef318ae6</gtr:id><gtr:otherNames>Hu R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:isbn>978-1-4244-7542-1</gtr:isbn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/E0887A8C-35CD-4487-AB73-4EE7D4184F9A"><gtr:id>E0887A8C-35CD-4487-AB73-4EE7D4184F9A</gtr:id><gtr:title>Storyboard sketches for content based video retrieval</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/281cfb64ed22ce9036425e90bd39c9d2"><gtr:id>281cfb64ed22ce9036425e90bd39c9d2</gtr:id><gtr:otherNames>JP Collomosse</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/5DF85AF3-ADF1-4853-8E17-CFDD96E10D08"><gtr:id>5DF85AF3-ADF1-4853-8E17-CFDD96E10D08</gtr:id><gtr:title>A bag-of-regions approach to sketch-based image retrieval</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/9fd17f711ed8bbbec34eec94ef318ae6"><gtr:id>9fd17f711ed8bbbec34eec94ef318ae6</gtr:id><gtr:otherNames>Hu R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>978-1-4577-1304-0</gtr:isbn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/BB54D9FC-DEEB-45D7-A567-70C8B4DB39A4"><gtr:id>BB54D9FC-DEEB-45D7-A567-70C8B4DB39A4</gtr:id><gtr:title>A performance evaluation of gradient field HOG descriptor for sketch based image retrieval</gtr:title><gtr:parentPublicationTitle>Computer Vision and Image Understanding</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/9fd17f711ed8bbbec34eec94ef318ae6"><gtr:id>9fd17f711ed8bbbec34eec94ef318ae6</gtr:id><gtr:otherNames>Hu R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/D055032/2</gtr:identifier></gtr:identifiers><gtr:projectHierarchy><gtr:parents><gtr:parent><gtr:id>4AAD269B-E294-4EFA-9196-94FD04112D9D</gtr:id><gtr:grantRef>EP/D055032/1</gtr:grantRef><gtr:amount>124589.89</gtr:amount><gtr:start>2006-12-01</gtr:start><gtr:end>2009-05-31</gtr:end><gtr:children><gtr:child rel="Transfer"><gtr:id>75AA68F2-B69B-4B60-BFAD-9CBD0A6E2547</gtr:id><gtr:grantRef>EP/D055032/2</gtr:grantRef><gtr:amount>22450.26</gtr:amount><gtr:start>2009-06-01</gtr:start><gtr:end>2009-10-31</gtr:end><gtr:children/></gtr:child></gtr:children></gtr:parent></gtr:parents></gtr:projectHierarchy><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>0F8B7B13-F2F5-42B3-95C6-EF12D7877319</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Multimedia</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>