<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.rcuk.ac.uk:80/organisation/E2F9CD01-D0AD-4610-8DD1-2AE1FED29D4B"><gtr:id>E2F9CD01-D0AD-4610-8DD1-2AE1FED29D4B</gtr:id><gtr:name>RFEL</gtr:name></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/4A348A76-B2D0-4DDD-804A-CE735A6D3798"><gtr:id>4A348A76-B2D0-4DDD-804A-CE735A6D3798</gtr:id><gtr:name>University of Bristol</gtr:name><gtr:department>Electrical and Electronic Engineering</gtr:department><gtr:address><gtr:line1>Senate House</gtr:line1><gtr:line4>Bristol</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BS8 1TH</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/4A348A76-B2D0-4DDD-804A-CE735A6D3798"><gtr:id>4A348A76-B2D0-4DDD-804A-CE735A6D3798</gtr:id><gtr:name>University of Bristol</gtr:name><gtr:address><gtr:line1>Senate House</gtr:line1><gtr:line4>Bristol</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BS8 1TH</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/536116AC-C155-4A24-A743-309BD68E50CE"><gtr:id>536116AC-C155-4A24-A743-309BD68E50CE</gtr:id><gtr:name>Defence Science &amp; Tech Lab DSTL</gtr:name><gtr:address><gtr:line1>Defence Science &amp; Tech Lab - MOD</gtr:line1><gtr:line2>Porton Down</gtr:line2><gtr:line4>Salisbury</gtr:line4><gtr:postCode>SP4 0JQ</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>CO_FUNDER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/E2F9CD01-D0AD-4610-8DD1-2AE1FED29D4B"><gtr:id>E2F9CD01-D0AD-4610-8DD1-2AE1FED29D4B</gtr:id><gtr:name>RFEL</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/A6B38CC8-A92D-41D6-8DC4-7ABEACF48E6B"><gtr:id>A6B38CC8-A92D-41D6-8DC4-7ABEACF48E6B</gtr:id><gtr:name>General Dynamics UK Ltd</gtr:name><gtr:address><gtr:line1>Bryn Brithdir</gtr:line1><gtr:line2>Oakdale Business Park</gtr:line2><gtr:postCode>NP12 4AA</gtr:postCode><gtr:region>Unknown</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/60D5ACA5-CD46-4D4F-B79D-0F574E16F291"><gtr:id>60D5ACA5-CD46-4D4F-B79D-0F574E16F291</gtr:id><gtr:firstName>David</gtr:firstName><gtr:surname>Bull</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/BB49C5DF-7238-41BD-B974-89A09506C76A"><gtr:id>BB49C5DF-7238-41BD-B974-89A09506C76A</gtr:id><gtr:firstName>Alin</gtr:firstName><gtr:otherNames>Marian</gtr:otherNames><gtr:surname>Achim</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/8D5D1B19-A9B7-43A8-81C0-7DA3DEAB0B80"><gtr:id>8D5D1B19-A9B7-43A8-81C0-7DA3DEAB0B80</gtr:id><gtr:firstName>Paul</gtr:firstName><gtr:otherNames>Richard</gtr:otherNames><gtr:surname>Hill</gtr:surname><gtr:roles><gtr:role><gtr:name>RESEARCHER_COI</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/861DC744-FFFA-4D15-B827-C652F7F7BB58"><gtr:id>861DC744-FFFA-4D15-B827-C652F7F7BB58</gtr:id><gtr:firstName>Nishan</gtr:firstName><gtr:surname>Canagarajah</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FH012710%2F1"><gtr:id>EFCECF9D-F989-4601-BBEA-13B6112FF981</gtr:id><gtr:title>Scalable Information Fusion: Adaptivity for Complex Environments and Secure Data</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/H012710/1</gtr:grantReference><gtr:abstractText>Visual analysis by human operators or service personnel is widely acknowledged to benefit from a fused representation, where images or video information from different spectral bands are combined into a single representation. To provide maximum utility fused data, or its constituent components, must be delivered in a timely manner, must facilitate simple and flexible processing and must be robust to loss and network congestion.Non infrastructure-based Mobile Ad-Hoc Networks are emerging as suitable platforms for exchanging and fusing real-time multi-sensor content. Such networks are characterised by the highly dynamic behaviour of the transmission routes and high path outage probabilities. They exemplify the type of complex, heterogeneous end-end transmission environments which will be commonly encountered in future military scenarios. The low-bandwidth, noisy nature of the physical channel in many sensor networks represents the most serious challenge to implementation of the digital battlefield of the future. One of the key challenges in such complex networking environments is the need to reliably transport and fuse real time video. Video is acknowledged to be inherently difficult to transmit and this is compounded by the need to support multiple sources to aid fusion and situational awareness while maintaining data security. We will focus our work on embedded video bitstreams (MPEG-4 (SVC) which offer scalability and enhanced flexibility for adaptation to varying channel types, interference levels, network structures and content types. These mitigate the need for highly inefficient video transrating processes and instead present a more tractable requirement in the form of dynamic bitstream management.A multisource approach to streaming is proposed which will support video fusion in a bandwidth-efficient manner while having the potential to significantly increase the robustness of real-time transmission in complex heterogeneous networks. Source coding and fusion will be based on the concept of scalability using an embedded bitstream. This means that the source need only be encoded once and that the coded representation can be truncated to support multiple diverse terminal types and to provide inherent congestion management without feedback. Such a system must be designed to maintain optimum fusion performance and hence intelligibility in the presence of bitstream truncation. The potential advantages of this scheme include:- A joint framework for scalable fusion and compression supporting both lossless and lossy representations. - Flexibility for optimisation depending on content type and application.- Graceful degradation: the capability of the fused video bitstream to adapt to differing terminal types and dynamic network conditions - Error resilience: the structure of the code stream can aid subsequent error correction systems alleviating catastrophic decoding failures.- Secure delivery: the ability to design encryption schemes which support truncation.- Region-of-Interest coding: supporting definition of ROIs for priority transmission.</gtr:abstractText><gtr:fund><gtr:end>2011-05-31</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2010-01-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>103457</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>RFEL</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Fusion Collaboration with RFEL</gtr:description><gtr:id>28BC762A-8122-41D2-8FA5-5655139332B7</gtr:id><gtr:piContribution>RFEL approached UoB, based on this grant to provide research direction and consultancy on optimised architectures and algorithms for video fusion. Support for R&amp;amp;D - optimised fusion algorithms and architectures.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>36000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>DSTL</gtr:description><gtr:end>2011-02-02</gtr:end><gtr:fundingOrg>Defence Science &amp; Technology Laboratory (DSTL)</gtr:fundingOrg><gtr:fundingRef>ITP UKG 6784</gtr:fundingRef><gtr:id>29856CBD-6105-42C0-8369-7A166FC73E6E</gtr:id><gtr:sector>Public</gtr:sector><gtr:start>2010-05-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>36000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>DSTL</gtr:description><gtr:end>2009-12-02</gtr:end><gtr:fundingOrg>Defence Science &amp; Technology Laboratory (DSTL)</gtr:fundingOrg><gtr:fundingRef>ITP UKG 6784</gtr:fundingRef><gtr:id>29AA5DD2-E22F-4F14-BDE0-9FBB7955E8F9</gtr:id><gtr:sector>Public</gtr:sector><gtr:start>2009-07-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>34000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>General Dynamics UK Ltd</gtr:description><gtr:fundingOrg>General Dynamics</gtr:fundingOrg><gtr:fundingRef>UoB/HH1</gtr:fundingRef><gtr:id>E9B60F73-98BD-4C30-A315-C680793D88AE</gtr:id><gtr:sector>Private</gtr:sector></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>34000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>General Dynamics UK Ltd</gtr:description><gtr:end>2008-12-02</gtr:end><gtr:fundingOrg>General Dynamics</gtr:fundingOrg><gtr:fundingRef>UoB/HH1</gtr:fundingRef><gtr:id>A2A0B298-EDBC-4411-9B2F-03D739B32BCA</gtr:id><gtr:sector>Private</gtr:sector><gtr:start>2008-04-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The work was performed in collaboration with General Dynamics who performed an assessment of the technology. The constraint on deployment was the use of a non-standardised codec. 

The methods developed were subsequently extended to deal with mitigating atmospheric distortions of images in collaboration with DSTL and GDUK</gtr:description><gtr:firstYearOfImpact>2011</gtr:firstYearOfImpact><gtr:id>28BDF0F2-3A55-41F8-8096-AA3DFC781176</gtr:id><gtr:impactTypes/><gtr:sector>Aerospace, Defence and Marine</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>This project introduced a new framework for joint scalable compression and fusion of video content in the compressed domain. Firstly, it demonstrated that compressed domain fusion is impossible for conventional video codecs due to drift introduced by multiple sets of interacting prediction loops. The proposed framework overcomes this by using a prediction-free compression technique based on a 3D Dual-tree Discrete Wavelet Transform (3D-DDWT) together with iterative noiseshaping, a novel non-expansive symmetrical wavelet boundary extension method and an efficient bitplane encoder. Fusion in the 3D-DDWT domain has been demonstrated to retain critical salient spatial and temporal information from all input sources. The new fusion method offers equivalent performance to the best frame-by-frame approach while eliminating associated temporal fusion artefacts. This system enables, for the first time, multi-source video fusion with the capability to create an embedded and quality-scalable bitstream, thus facilitating a flexible and reliable approach for delivery of fused content under dynamic network conditions.</gtr:description><gtr:exploitationPathways>The findings would be applicable in defence or security applications where communication of multi-sensor data occurs over a network with dynamic bandwidth variations. In such cases it is often necessary to change the video bandwidth and retain security. Conventionally this is done by decrypting and then transcoding and then re-encrypting. Our system enables, for the first time, multi-source video fusion with the capability to create an embedded and quality-scalable bitstream, thus facilitating a flexible and reliable approach for delivery of fused content under dynamic network conditions.</gtr:exploitationPathways><gtr:id>A7EFB4F4-0995-4754-9F08-3B2B47610B23</gtr:id><gtr:sectors><gtr:sector>Aerospace, Defence and Marine,Digital/Communication/Information Technologies (including Software),Healthcare,Security and Diplomacy,Transport</gtr:sector></gtr:sectors><gtr:url>http://www.bristol.ac.uk/vi-lab/projects/udtcwt/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/9128228C-3088-4FBC-B1C4-58538EFB4EBA"><gtr:id>9128228C-3088-4FBC-B1C4-58538EFB4EBA</gtr:id><gtr:title>The Undecimated Dual Tree Complex Wavelet Transform and its application to bivariate image denoising using a Cauchy model</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/e6347e7c549c8b91ab9bdc2334ae3018"><gtr:id>e6347e7c549c8b91ab9bdc2334ae3018</gtr:id><gtr:otherNames>Hill P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:isbn>978-1-4673-2534-9</gtr:isbn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/2D42D9F5-8D69-4FC4-958D-796B353E814E"><gtr:id>2D42D9F5-8D69-4FC4-958D-796B353E814E</gtr:id><gtr:title>Automatic contrast enhancement of low-light images based on local statistics of wavelet coefficients</gtr:title><gtr:parentPublicationTitle>Digital Signal Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/3f47151568d10f2862cba0b49202b11c"><gtr:id>3f47151568d10f2862cba0b49202b11c</gtr:id><gtr:otherNames>Loza A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/A955761F-1D83-4673-BC8D-931B402B5470"><gtr:id>A955761F-1D83-4673-BC8D-931B402B5470</gtr:id><gtr:title>Scalable fusion using a 3D dual tree wavelet transform</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/e6347e7c549c8b91ab9bdc2334ae3018"><gtr:id>e6347e7c549c8b91ab9bdc2334ae3018</gtr:id><gtr:otherNames>Hill P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>978-1-84919-661-1</gtr:isbn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/195C4A68-5B58-44FC-9A4E-32EB39535266"><gtr:id>195C4A68-5B58-44FC-9A4E-32EB39535266</gtr:id><gtr:title>Dual-tree complex wavelet coefficient magnitude modelling using the bivariate Cauchy-Rayleigh distribution for image denoising</gtr:title><gtr:parentPublicationTitle>Signal Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/e6347e7c549c8b91ab9bdc2334ae3018"><gtr:id>e6347e7c549c8b91ab9bdc2334ae3018</gtr:id><gtr:otherNames>Hill P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/118EFDBC-F38C-4540-8B67-6F48125843A3"><gtr:id>118EFDBC-F38C-4540-8B67-6F48125843A3</gtr:id><gtr:title>Scalable video fusion</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/e6347e7c549c8b91ab9bdc2334ae3018"><gtr:id>e6347e7c549c8b91ab9bdc2334ae3018</gtr:id><gtr:otherNames>Hill P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/H012710/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>12FC01EE-4952-4AE4-883A-D3E83A89C5C6</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Digital Signal Processing</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>